---

title: Kafka Connect를 활용한 CDC 파이프라인 구축 (Source, Sink Pipeline)
date: 2024-05-07
categories: [Kafka, CDC]
tags: [Kafka, CDC]
layout: post
toc: true
math: true
mermaid: true

---

[실습 템플릿](https://github.com/K-Diger/kafka-cdc-template)

위 레포지토리가 구축하고자하는 환경은 각기 다른 온프레미스 서버 인스턴스에 카프카를 KRaft모드로 띄우고 CDC를 구축하는 것이다.

따라서 각 노드에는 `Controller`, `Broker`, `Connect` 총 3개의 프로세스가 동작하는 환경을 구축한다.

---

# Step 1. MSSQL 접속 및 데이터베이스, 스키마, 테이블 생성

1. `SOURCE`, `EXTERNAL` 데이터베이스를 생성
2. `SOURCE`, `SOURCE` 데이터베이스 내에 `dbo` 스키마를 사용
3. `SOURCE`, `SOURCE` 데이터베이스 내에 `dbo` 스키마 내에 `MEMBER_BASE` 테이블 생성

```sql
-- SOURCE 라는 데이터베이스를 사용
USE [EXTERNAL];

create table dbo.MEMBER_BASE(
    member_id bigint primary key,
    nickname nvarchar(50)
)

USE SOURCE;

create table dbo.MEMBER_BASE(
    member_id bigint primary key,
    nickname nvarchar(50)
)

EXEC sys.sp_cdc_enable_db;

ALTER DATABASE SOURCE SET CHANGE_TRACKING = ON(CHANGE_RETENTION = 3 DAYS, AUTO_CLEANUP = ON)

EXEC sys.sp_cdc_enable_table
      @source_schema = 'dbo',
      @source_name = 'MEMBER_BASE',
      @role_name = 'sa';
```

---

# Step 2. Source, Sink Connector 등록

HTTP 요청으로 `http://localhost:8083/connectors` 혹은 `http://localhost:8084/connectors` 혹은 `http://localhost:8085/connectors` 으로 DB에 관한 커넥트를 등록한다. 이 때 메서드는 POST 요청으로 보내야하며, Requset Body는 아래와 같다.

## 1. 소스 커넥터 등록 [POST] http://localhost:8083/connectors
```json
{
    // 기본값: 없음 (필수 설정)
    // 다른 옵션: 사용자가 지정한 어떤 문자열이든 가능함
    "name": "mssql-cdc-member-source-connector",
    "config": {
        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 source connector 클래스 (예: MySqlConnector, PostgresConnector 등)
        "connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",

        // 기본값: 1
        // 다른 옵션: 1보다 큰 정수 (병렬 처리를 위해 증가 가능)
        "tasks.max": "1",

        // 기본값: false
        // 다른 옵션: true (SSL/TLS를 사용한 암호화된 연결)
        "database.encrypt": false,

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: SQL Server가 실행 중인 다른 호스트 이름이나 IP 주소
        "database.hostname": "host.docker.internal",

        // 기본값: 1433 (SQL Server의 기본 포트)
        // 다른 옵션: SQL Server가 사용하는 다른 포트 번호
        "database.port": "1433",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 데이터베이스에 접근 권한이 있는 다른 사용자 이름
        "database.user": "SA",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 해당 사용자의 올바른 비밀번호
        "database.password": "admin123$%",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 데이터베이스 이름 또는 여러 데이터베이스 (쉼표로 구분)
        "database.names": "SOURCE",

        // 기본값: 없음
        // 다른 옵션: 다른 스키마 이름 또는 여러 스키마 (쉼표로 구분)
        "schema.include.list": "dbo",

        // 기본값: 없음
        // 다른 옵션: 다른 테이블 이름 또는 여러 테이블 (쉼표로 구분)
        "table.include.list": "dbo.MEMBER_BASE",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: Kafka 브로커의 다른 주소와 포트
        "database.history.kafka.bootstrap.servers": "broker1:19091,broker2:29092,broker3:39093",

        // 기본값: 없음
        // 다른 옵션: 다른 유효한 타임존 ID
        "db.timezone": "Asia/Seoul",

        // 기본값: 서버 이름
        // 다른 옵션: 사용자가 지정한 다른 접두사
        "topic.prefix": "member-source",

        // 기본값: 없음
        // 다른 옵션: 다른 transform 이름 또는 여러 transform (쉼표로 구분)
        "transforms": "route",

        // 기본값: 없음
        // 다른 옵션: 다른 Kafka Connect transform 클래스
        "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",

        // 기본값: 없음
        // 다른 옵션: 다른 정규식 패턴
        "transforms.route.regex": "member-source.SOURCE.dbo.MEMBER_BASE",

        // 기본값: 없음
        // 다른 옵션: 다른 대체 문자열
        "transforms.route.replacement": "source",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: Kafka 브로커의 다른 주소와 포트
        "schema.history.internal.kafka.bootstrap.servers": "broker1:19091,broker2:29092,broker3:39093",

        // 기본값: ${database.server.name}.schema-changes.inventory
        // 다른 옵션: 사용자가 지정한 다른 토픽 이름
        "schema.history.internal.kafka.topic": "schema-history-cdc"
    }
}
```



## 2. 싱크 커넥터 등록 [POST] http://localhost:18083/connectors
```json
{
    // 기본값: 없음 (필수 설정)
    // 다른 옵션: 사용자가 지정한 어떤 문자열이든 가능함
    "name": "mssql-cdc-member-sink-connector",
    "config": {
        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 sink connector 클래스 (예: ElasticsearchSinkConnector, S3SinkConnector 등)
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 데이터베이스 URL (예: MySQL, PostgreSQL 등의 JDBC URL)
        "connection.url": "jdbc:sqlserver://host.docker.internal:1433;databaseName=EXTERNAL",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 데이터베이스에 접근 권한이 있는 다른 사용자 이름
        "connection.user": "sa",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 해당 사용자의 올바른 비밀번호
        "connection.password": "admin123$%",

        // 기본값: false
        // 다른 옵션: true (테이블이 존재하지 않을 경우 자동으로 생성)
        "auto.create": "false",

        // 기본값: false
        // 다른 옵션: true (스키마 변경 시 테이블 구조를 자동으로 변경)
        "auto.evolve": "false",

        // 기본값: false
        // 다른 옵션: true (현재 설정된 값, 삭제 작업 활성화)
        "delete.enabled": "true",

        // 기본값: 1
        // 다른 옵션: 1보다 큰 정수 (병렬 처리를 위해 증가 가능)
        "tasks.max": "1",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 토픽 이름 또는 여러 토픽 (쉼표로 구분)
        "topics": "member-source.SOURCE.dbo.MEMBER_BASE",

        // 기본값: 없음 (필수 설정)
        // 다른 옵션: 다른 테이블 이름 형식 (예: "${topic}" 사용 가능)
        "table.name.format": "EXTERNAL.dbo.MEMBER_BASE",

        // 기본값: none
        // 다른 옵션: record_value, record_key (현재 설정), fields
        "pk.mode": "record_key",

        // 기본값: insert
        // 다른 옵션: upsert (현재 설정), update
        "insert.mode": "upsert",

        // 기본값: 없음
        // 다른 옵션: 다른 transform 이름 또는 여러 transform (쉼표로 구분)
        "transforms": "unwrap",

        // 기본값: 없음
        // 다른 옵션: 다른 Kafka Connect transform 클래스
        "transforms.unwrap.type": "org.apache.kafka.connect.transforms.ExtractField$Value",

        // 기본값: 없음
        // 다른 옵션: 추출하고자 하는 다른 필드 이름
        "transforms.unwrap.field": "after"
    }
}
```

---

# Step 3. 테스트

이제 DB의 데이터를 삭제하고 생성하고 변경하는 등 쓰기요청을 수행한 후에 `http:://localhost:8080` 카프카 UI로 들어가서 CDC내용에 관한 토픽 메세지를 확인한다.

```sql
USE SOURCE;

insert into dbo.MEMBER_BASE(member_id, nickname) values (1, 'testNickname1');
insert into dbo.MEMBER_BASE(member_id, nickname) values (2, 'testNickname2');
insert into dbo.MEMBER_BASE(member_id, nickname) values (3, 'testNickname3');
insert into dbo.MEMBER_BASE(member_id, nickname) values (4, 'testNickname4');
insert into dbo.MEMBER_BASE(member_id, nickname) values (5, 'testNickname5');
insert into dbo.MEMBER_BASE(member_id, nickname) values (6, 'testNickname6');
insert into dbo.MEMBER_BASE(member_id, nickname) values (7, 'testNickname7');
insert into dbo.MEMBER_BASE(member_id, nickname) values (8, 'testNickname8');
insert into dbo.MEMBER_BASE(member_id, nickname) values (9, 'testNickname9');
insert into dbo.MEMBER_BASE(member_id, nickname) values (10, 'testNickname10');
```

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/cdc/KafkaUIHome.png?raw=true)

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/cdc/KafkaUIMessages.png?raw=true)

```json
"payload": {
  "before": null,
  "after": {
    "member_id": 1,
    "nickname": "testNickname1"
  },
}
```
위 항목으로 데이터가 어떻게 변경되었는지(생성, 변경, 삭제)를 파악할 수 있다.

### 생성
```json
"payload": {
  "before": null,
  "after": {
    "member_id": 1,
    "nickname": "testNickname1"
  },
}
```

### 수정
```json
"payload": {
  "before": {
    "member_id": 1,
    "nickname": "testNickname1"
  },
  "after": {
    "member_id": 1,
    "nickname": "testModifiedNickname1"
},
```

### 삭제
```json
"payload": {
    "before": {
        "member_id": 2,
        "nickname": "testNickname2"
    },
    "after": null,
}
```

---

# 이론으로

[로그 기반 CDC 5가지 장점](https://debezium.io/blog/2018/07/19/advantages-of-log-based-change-data-capture/)

Debezium을 사용하는 Source CDC는 로그 기반으로 동작하게된다.

즉, DBMS의 binlog를 활용하여 변경된 데이터를 감지하게 되는 것인데 이 방식의 구체적인 내용과 장점을 살펴본다.

## Binary Log

[MySQL 공식문서 - BinaryLog](https://dev.mysql.com/doc/refman/8.4/en/binary-log.html)

Binary Log는 데이터베이스의 변경 사항을 기록하는 기능이다. 주로 소스 서버의 변경 사항을 레플리카 서버로 전송하는 데이터`복제`나 백업 이후의 변경 사항을 재실행하여 최신 상태로 `복구`할 때 활용된다.

바이너리 로그는 예상치 못한 중단이 일어날 때를 대비하여 완전히 완료된 트랜잭션만 기록하고 다시 읽는 방식으로 동작한다.

즉, 트랜잭션이 끝나지 않은 내용은 이후 BinaryLog에 기록되지 않아 DB에 적용되지 않는다.

참고로, `Debezium`을 MySQL 사용하기 위해 Binary Log를 활용한다는 내용이었지만 `MSSQL`, `PostgreSQL`등 각자만의 Binary Log의 역할을 하는 개념을 도입시키거나 DBMS단위에서 자체적인 CDC를 제공한다.

---

## Global Transaction ID - GTID

[MySQL 공식문서 - Replication](https://dev.mysql.com/doc/refman/8.4/en/replication.html)

MySQL에서는 Binary Log방식이 아닌 Transaction ID를 통해 복제를 수행하는 GTID방식도 존재한다.

