---

title: 기본이 중요하다
date: 2023-09-30
categories: []
tags: []
layout: post
toc: true
math: true
mermaid: true

---

# SUWIKI

## 1. 강의평가 작성 시 비관적 락을 활용한 동시성 문제를 해결

### 문제 상황

A라는 강의 레코드에 X, Y 가 각각 값을 올리고 내리는 요청이 동시에 발생했다.

레코드의 값을 증가시키기위 위해 SELECT 하는 구문과, 값을 감소시키기 위해 SELECT 하는 구문이 동시에 발생했고

커밋되는 시점이 달라 값을 증가시킨 요청이 커밋되었음에도 값을 감소시키는 요청이 커밋되어 변경사항을 덮어 씌우는 현상이 발생했다.

동시성 문제를 해결하는 방법을 알아보는 중 DBMS에서 충돌이 발생하지 않는 상황을 가정하여 애플리케이션 단위에서 동시성을 처리하는 낙관적 락과 DBMS에서 충돌이 발생하는 상황을 가정하는 비관적 락의 차이를 학습하고 비관적 락을 적용하여 해결하기로 결정했다.

이 방법을 적용하게 된 근거로는 각 방식의 장/단점을 따져보았는데

### 낙관적 락의 장/단점으로는

- 실제로 Lock을 거는 것이 아니기 때문에 성능저하의 우려가 없다.
- 하지만 충돌이 발생해서 롤백을 해야하는 경우 수동으로 해당 데이터의 내용을 모두 롤백하는 로직을 만들어야해서 복잡해질 수 있다.

### 비관적 락의 장/단점으로는

- Lock을 통해 데이터의 무결성을 보장할 수 있다. 그리고 그럼에도 충돌이 발생했을 경우에는 롤백연산을 한 번만 수행해도 된다.
- 하지만 Lock을 거는 것으로 인한 리소스 경쟁으로 성능 저하가 발생할 수 있다.

### 왜 비관적 락을 적용하였는가?

- 실제로 DBMS에서 충돌이 난 것으로인해 데이터 무결성이 깨졌기 때문이다.

### 비관적 락 중 어떤 락을 사용하였는가?

그리고 비관적 락에도 종류가 있는데 특정 레코드에 접근했을 때 다른 트랜잭션에서 읽기만 가능하게 하는 `공유 락`, 읽기 및 쓰기 모두 불가능한 `베타 락`이라는 종류가 있다.

이 차이점을 알아본 후 JPA가 지원하는 `@Lock`애노테이션의 `PessimisticWrite`옵션을 활용했다.

이 옵션은 베타락을 지원하는 것으로 `SELECT FOR UPDATE` 구문을 보낼 수 있도록 하는 옵션이다.

`SELECT FOR UPDATE`는 어떤 트랜잭션이 데이터를 수정하기위해 SELECT를 할 때 다른 트랜잭션에서 접근하지 못하도록 Lock을 거는 쿼리 구문이다.

이 처럼 다른 트랜잭션에서 수정을 위해 접근하지 못하도록 해야하기 때문에 `SELECT FOR UPDATE`구문의 필요성을 느꼈고 이 때문에 베타락을 사용했다.

### 락을 사용하지 않고 이 문제를 해결할 방법은 없었을까?


### DBMS의 격리수준으로는 어떤 것들이 있나?

- `Read Uncommitted`
  - 커밋, 롤백 여부에 상관없이 다른 트랜잭션에서 읽을 수 있다.
  - `Dirty Read` 현상 발생 (다른 트랜잭션에서 처리한 작업이 완료되지 않았음에도 불구하고 다른 트랜잭션에서 볼 수 있게 되는 현상)

- `Read Committed`
  - 커밋이 완료된 트랜잭션의 변경사항만 다른 트랜잭션에서 읽을 수 있다.
  - `Dirty Read` 현상 해결
  - `NON-REPEATABLE-READ` 현상 발생 (하나의 트랜잭션 내에서 동일한 SELECT 쿼리를 실행했을 때 항상 같은 결과를 보장하지 않는 것)
    - A 트랜잭션에서 SELECT
    - B 트랜잭션에서 UPDATE 후 커밋
    - A 트랜잭션에서 다시 SELECT
    - 위 상황에서 두 번의 SELECT가 `같은 레코드의 값`을 반환하지 않는다.

- `Repeatable Read`
  - 트랜잭션이 시작되기 전에 커밋된 내용에 관해서만 조회할 수 있다.
  - `NON-REPEATABLE-READ` 현상 해결
  - `Phantom Read` 발생
    - A 트랜잭션에서 SELECT
    - B 트랜잭션에서 INSERT/DELETE 후 커밋
    - A 트랜잭션에서 다시 SELECT
    - 위 상황에서 두 번의 SELECT가 같은 `레코드의 갯수`를 결과를 반환하지 않는다.

- `Serializable`
  - 테이블 내 모든 레코드에 접근 불가능
  - 모든 데이터 부정합 문제 해결

---

## JWT를 활용한 토큰 기반 인증 vs 세션 기반 인증

### JWT를 활용한 토큰 기반 인증 방식 장/단점

- 장점 1. 확장성과 분산화
  - JWT는 토큰을 생성하고 검증하는 키를 기반으로 동작하며, 토큰에 필요한 정보를 담을 수 있어서 서버 간에 토큰을 공유하거나 전달할 수 있어 확장성이 뛰어나고 분산 환경에서 사용하기 용이하다.

- 장점 2. 상태 없음(Stateless)
  - 서버 측에서 토큰을 검증하고 필요한 정보를 추출하므로, 서버는 클라이언트의 상태를 저장할 필요가 없어 리소스가 절약 될 수 있다.

- 장점 3. 유연한 사용자 권한 관리
  - 토큰 내에 사용자 권한과 관련된 정보를 포함하여 사용자 권한 관리가 용이하며, 토큰의 내용을 이용하여 권한 검사를 수행할 수 있다.

- 단점 1. 토큰 크기와 보안
  - JWT는 탈취될 가능성이 있다. 중요한 정보를 토큰에 포함시키면 보안 문제가 발생할 수 있다.

- 단점 2. 토큰 유효성 검증의 어려움
  - 토큰이 변조되지 않았는지 확인하기 위해 서명을 검증해야 하기 때문에 서명 검증 과정이 추가로 필요하며, 이에 따른 복잡성이 발생할 수 있다.

### 서버 측 세션(Session) 기반 인증 방식 장/단점

- 장점 1. 보안성
  - 세션은 서버에 저장되므로 클라이언트에 노출되지 않는다. 토큰 기반 인증에 비해 보안성이 높다.

- 장점 2. 세션 탈취 시 대처가능
  - 세션을 사용하면 만료 시간을 쉽게 조절하고 조절할 수 있으며, 만료 시간이 지나면 자동으로 세션을 무효화시킬 수 있다.

- 단점 1. 상태 유지
  - 세션은 서버 측에서 상태를 유지해야 하므로, 서버의 메모리를 사용하게 되어 클라이언트가 많을 때 성능 저하가 발생할 수 있다.

- 단점 2. 확장성
  - 분산 환경에서 각 서버마다 발급하는 세션을 관리하기 위해 세션 클러스터를 운영해야하는 복잡성이 증가한다.


### 공격자로부터 클라이언트의 세션이 탈취되었음을 서버측에서는 어떻게 알 수 있을까?

- 클라이언트의 세션 ID가 이전에 없던 위치에서 사용되었거나, 단기간 내에 많은 요청이 발생하는 경우 이상행동으로 간주하여 해당 세션을 무효화한다.

- 클라이언트의 로그인 위치를 기록하고, 동일한 세션 ID가 다른 지역에서 사용되는 경우 해당 세션을 무효화한다.

---

## 2. 테스트 환경을 개선하여 테스트 코드 작성으로 발생할 생산성 저하 문제 개선

기존에는 테스트 환경이 전혀 마련되어있지 않고 Postman으로 일일히 E2E테스트를 하는게 전부였다.

때문에 실제 프로덕트에서 예상치 못한 버그가 발생한 경우가 조금씩 나오게 되면서 테스트 프레임워크를 활용한 자동화된 테스트 환경을 도입하기로 했다.

그런데, 이미 발생한 버그들을 찾기 위해선 빠르게 테스트 환경을 마련해야할 필요가 있었는데 이 때 통합 테스트를 작성하되 사용자의 행위에 대한 시나리오에 대응할 수 있는 테스트 템플릿을 만들어야겠다고 생각했다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/0bb8bed9-80a2-4478-93dd-b2d78927865c)

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/0deccb5b-eaeb-452b-8b50-44fe7410add1)

위 그림은 해당 테스트 템플릿의 일부이다. 위 SQL 구문을 활용, 테스트 베이스 객체를 상속받으면 통합테스트를 아주 간편하게 작성할 수 있게 된다.

### 테스트 대역의 종류는 무엇이 있을까?

우선 테스트 대역이란, 실제 객체가 아닌 단순한 객체를 이용하여 테스트하는 것을 말한다.

- Mock (행위에 집중하기 위함)
  - Mock (실제 객체의 동작을 모방한 가짜 객체)
    - Mock은 실제 객체를 완전히 대체한다.
    - Spy와 달리 해당 객체의 일부분만을 스텁으로 대체할 수 없다.

  - Spy (실제 객체를 기반으로 생성된 가짜 객체)
    - 실제 메서드가 실행되고 그 메서드가 실제로 테스트된다.
    - 또한 일부분을 스텁으로 대체할 수 있다.

- Stub (상태에 집중하기 위함)
  - Stub (mock객체의 기대 행위(when() ~~ then())를 작성하여 테스트에서 원하는 상황을 작성하는 것을 Stub이라한다.)
  - Dummy (객체가 필요하지만 내부 기능이 필요하지는 않을 때 사용)
  - Fake (실제로 사용된 객체는 아니지만 같은 동작을 하는 구현된 객체이다.(원래 객체의 단순화된 버전))

---

### 테스트 대역이 왜 필요한가?

```text
1. OrderRepository.findOrderList()로 기존 주문서 조회
2. 주문서가 있다면 중복으로 간주해 OrderDuplicateException 발생
3. OrderRepository.createOrder()로 주문서 생성
4. Argument로 넘어온 isNotify가 true이면 NotificationClient.notifyToMobile() 를 이용해 알림 발생
```

위와 같은 OrderService의 createOrder() 비즈니스 로직 시나리오가 있다고 가정했을 때 OrderService의 로직을 테스트하려면 아래 절차가 반드시 필요하다.

- OrderRepository가 사용할 RDB connection 세팅
- RDB에 로직 테스트 조건에 맞는 데이터 세팅
- NotificationClient가 사용할 Notification Server 연결
- Notification이 성공했을 때의 데이터 롤백 처리

이러한 선행 조건이 많아지게 될수록 테스트는 느려지고 복잡도가 증가하게 된다. 또한 외부의 영향으로 로직 자체를 테스트 못하는 경우도 생길 수 있다.

이런 문제 영역을 `메소드의 실제 내부 동작은 실행되지 않고` 상황 설정만 할 수 있도록 해결한 것이 `테스트 대역`이다.

### Mockito를 사용하여 외부 의존성을 제거하여 테스트 작성

```java
public class MockitoTest {
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange
        OrderRepository orderRepository = Mockito.mock(OrderRepository.class);
        NotificationClient notificationClient = Mockito.mock(NotificationClient.class);
        orderService = new OrderService(orderRepository, notificationClient);

        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

### @Mock 애노테이션을 사용하여 Mock 객체 더 쉽게 만들기

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Mock
    private OrderRepository orderRepository;

    @Mock
    private NotificationClient notificationClient;

    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange
        orderService = new OrderService(orderRepository, notificationClient);

        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- 한 가지 주의 할 점은 @ExtendWith(MockitoExtension.class)를 사용해야지만 테스트 시작전 어노테이션을 감지해서 mock 객체를 주입하기 때문에 꼭 함께 사용해야 한다.

- 또한 실제 테스트 대상은 다른 의존성에 대한 Mock 과 달리 Stub을 지정해주지 않았는데 `Mockito의 기본전략`이 `Answers.RETURNS_DEFAULTS`이 이를 해결해준 것이다.
  - 이로 인해 아무런 내용이 없는 메서드가 타입에 맞게 (void) 실행된 것이다.

### @InjectMocks 애노테이션을 사용하여 테스트 대상 Mock 객체에 Mock 의존성 주입하기

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Mock
    private OrderRepository orderRepository;

    @Mock
    private NotificationClient notificationClient;

    @InjectMocks
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- @InjectMocks 애노테이션을 활용하면 Arrange 범위에서 의존성을 주입해줄 필요가 없게 된다.

### @Spy 애노테이션을 활용하기

OrderRepository의 메소드 중 createOrder()는 stub하고 findOrderList()는 실제 기능을 그대로 사용하고 싶을 때 `Spy`를 사용하면 좋다.

Spy는 Mock과 달리 객체의 전체를 대체하는 것이 아닌 일부분만 대체하여 사용하는 것이 가능하다.

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Spy
    private OrderRepository orderRepository;

    @Spy
    private NotificationClient notificationClient;

    @InjectMocks
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("Spy 객체로, OrderRepository의 CreateOrder 메서드를 Stub으로 대체한다.");
            return null;
        }).when(orderRepository).createOrder();

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- 이렇게 특정 객체의 특정 메서드만 스텁으로 대체해서 사용하고 싶다면, Spy를 쓸 수 있고, 스텁으로 대체하지 않은 메서드는 실제 메서드로 사용된다.

### @MockBean 애노테이션 활용하기 (@SpringBootTest)

```java
@SpringBootTest
class BasicSpringTests {

    @Autowired
    private OrderService orderService;

    @Test
    void createOrderTest() {
        orderService.createOrder(true);
    }
}
```

위 코드는 실제 모든 빈과 Ioc/DI 컨테이너를 다 띄우고 테스트한다. 따라서 테스트 대역을 사용하지 않았을 때의 문제점을 모두 안고가는 테스트이다.

이 과정을 더 단축시키기 위해 @MockBean 애노테이션이 쓰인다. 이 애노테이션은 컨테이너에 실제 객체가 아닌 Mock객체를 등록하게한다.

```java
@SpringBootTest
class BasicSpringTests {

    @MockBean
    private OrderRepository orderRepository;

    @MockBean
    private NotificationClient notificationClient;

    @Autowired
    private OrderService orderService;

    @Test
    void createOrderTest() {
        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("MockBean 애노테이션으로 만들어진 OrderRepository를 사용한다.");
            return Collcetions.emptyList();
        });
        // Arrange - Stub
        Mockito.doAnsewr(invocation -> {
            System.out.println("MockBean 애노테이션으로 만들어진 NotificationClient를 사용한다.");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- `@Mock` 애노테이션이 달린 객체는 `@InjectMocks`에 주입된다.
- `@MockBean` 애노테이션이 달린 객체는 `@SpringBootTest`에 주입된다.

---

## 3. Caffeine Cache를 활용하여 홈 API 응답시간 개선

### 왜 홈 API에 캐시를 적용했는가?

캐싱의 대상은 자주 변하지 않고 조회 요청이 빈번하게 일어나는 데이터가 적절하다.

홈 API가 보여주는 데이터는 빈번하게 변경되지 않지만 사용자들이 가장 많이 조회하는 API이기 때문에 캐싱을 적용하기로 판단했다.

### 캐싱된 데이터가 가장 최신의 데이터라는 것을 판별할 수 있는 방법은?

서버에서 캐시가 업데이트될 때마다 캐시의 버전을 업데이트하고 클라이언트는 요청할 때 버전을 함께 전달하도록 한다.

서버는 현재 버전과 클라이언트가 전달한 버전을 비교하여 최신인지 확인하여 데이터의 최신화 여부를 판별하면 될 것 같다.

### 왜 Caffeine Cache를 적용했는지?

- 캐시 전략에 우선순위를 부여 가능하다.
- 캐시 히트율이 매우 높은 알고리즘인 `Window TinyLFU`를 제공한다.

### Caffeine 캐싱 데이터 저장 방식

- JVM Heap 메모리 내에 저장된다.

### Caffeine 캐싱 전략

Caffeine의 캐싱 전략을 살펴보자

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84pKiujtGOpbnpVgIwhpkQ.png)

- `Main Cache`가 존재하며 전체 용량의 99%를 가지고 있다. (Segmented LRU)
    - `Main Cache`의 20%를 차지하는 `Probation Cache`가 존재한다.
        - 새로운 데이터가 `Probataion`영역에 저장되어야 할 때, `Probation`영역의 데이터와 LRU로 비교하여 `Evict`를 수행한다.
            - `Probation` 영역에 일정 횟수 이상 접근되면 `Protected Cache`로 옮겨진다.(LFU)
    - `Main Cache`의 80%를 차지하는 `Protected Cache`가 존재하며 이 공간의 데이터는 제거되지 않는다.
        - `Protected Cache` **영역이 꽉차면 오래된 데이터는 쫓겨난다.(LRU)**
        - 이 때 쫓겨난 데이터는 `TinyLFU` 알고리즘에 의해 제거되거나 `Main Cache`의 `Probation Cache` 영역으로 옮겨진다.

- `Window Cache`가 존재하여 전체 용량의 1%를 가지고 있다.
    - 새로운 데이터가 쓰일 때 가장 먼저 이 공간에 쓰인다.
    - `Window Cache`가 꽉차있다면 `LRU`로 비교하여 기존 데이터를 쫓아낸다. **(제거되는 게 아님)**
        - 이 쫓아내진 데이터는 `Tiny LFU` 알고리즘으로 `Probation Cache`와 비교하여 `Probation Cache`에 저장되거나 승격하지 못하면 제거된다.

여기서 사용되는 `TinyLFU`의 정책을 살펴보기 전 우선 용어 정리는 다음과 같다.

- `Window Cache`, `Main Cache내의 Protected Cache`로부터 제거되는 데이터는 `Candidate`이다.
- `Main Cache 내의 Probation Cache`에서 제거되는 데이터는 `Victim`이다.

`TinyLFU`의 정책은 아래와 같다.

- `Candidate Cache` 접근 횟수 > `Victim Cahce` 접근 횟수 -> `Victim 제거`
- `Candidate Cache` 접근 횟수 < `Victim Cahce` 접근 횟수 && `Candidate` 접근 횟수가 5회 미만 -> `Candidate 제거`
- 둘 중 하나 `랜덤하게 제거`

정리하자면 `Window TinyLFU` 알고리즘은

- `Window Cache`에 있는 새로운 데이터가 `Probation` 영역으로 승격시킬 지 제거할 지 판단할 때 사용하는 알고리즘이다.
    - 승격하지 못하면 제거된다.

- `Protected Cache`의 용량이 꽉 찼을 때 `Probation` 영역에서 승격될 대상과 비교할 때 사용하는 알고리즘이다.
    - 여기서 기존 `Protected Cache`의 데이터는 제거되거나 `Probation` 영역으로 강등된다.

---

### Local Cache - Ehcache vs Caffeine

[벤치마크 결과](https://github.com/ben-manes/caffeine/wiki/Benchmarks)

위 벤치마크 결과를 본다면 압도적으로 카페인 캐시가 성능이 좋게 나온다.

성능이 좋다고 무조건 쓰는게 좋은 것은 아니므로 기존 환경을 잘 고려하여 선택하면 될 것 같다.

### 성능 개선 측정은 어떻게 했는지?

포스트맨으로 약 30회 측정했다. 그 이후 평균 값을 통해 성능을 측정했다.

---

# SUGO

## 1. @Async 애노테이션을 사용하여 81% 성능 개선

### 문제 상황

클라이언트에 푸쉬 알림을 전송하기 위해 FCM 서버에 요청하는 로직을 추가했더니 아래와 같이 658ms가 소요되는 현상이 발생했다.

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/async/%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0%20%EC%9D%B4%EC%A0%84%20%EB%91%90%EB%B2%88%EC%A7%B8%20%EC%9A%94%EC%B2%AD.jpg?raw=true)

이 메서드를 추가하기 전에는 100ms도 넘지 않았던 응답시간이 저렇게 급격하게 늘어나니 클라이언트단에서도 응답을 기다리느라 사용자 경험을 해치는 상황이 발생하게 되었다.

### 어떻게 속도를 빠르게 할 수 있을까?

외부 서버를 호출하는 로직을 비동기로 처리하면 어떨까? 굳이 외부 서버로 던진 요청이 완료된 것을 확인받은 후에 다른 비즈니스 로직을 처리해야할까? 를 고민하다가 직접 비동기 메서드를 적용해보기로 했다.

### ThreadPoolTaskExecutor와 @Async

[Asynchronous calls in spring](https://www.linkedin.com/pulse/asynchronous-calls-spring-boot-using-async-annotation-omar-ismail/)

Spring에서 비동기 작업을 처리하려면 다음 두 가지를 관리해야한다.

- @Asnyc 애노테이션으로 비동기 메서드를 지정한다.
- 비동기 메서드의 처리를 담당하는 스레드 풀을 관리해줘야한다.

스레드 풀을 관리하기 위한 Bean을 등록하기 위해서는 아래의 인터페이스의 구현체를 셋팅해줘야 한다.

```java
public interface AsyncConfigurer {

	@Nullable
	default Executor getAsyncExecutor() {
		return null;
	}

	@Nullable
	default AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
		return null;
	}

}
```

하지만 꼭 위 인터페이스를 구현체로 등록하지 않아도 되긴하다. 그냥 ThreadPoolTaskExecutor를 반환하는 메서드를 Bean으로 등록해주면 되는 것일 뿐이다.

### @Async 애노테이션이 어떻게 동작하는건가?

- @Async 애노테이션이 붙은 메서드가 실행될 때, 프록시가 해당 호출을 가로채고 Task Executor에 전달한다.

- Task Executor는 새로운 스레드를 생성하고 해당 스레드에서 호출된 로직을 실행한다. 그리고 이 때 이 메서드의 리턴을 기다리지 않고 다른 작업을 계속 수행한다.

- 이전에 호출시킨 메서드가 리턴되었다면 Task Executor에 결과를 반환한다.

이 때 새로운 스레드를 생성한다는 점이 성능 저하의 문제가 될 수 있다.

```java
public class ThreadPoolTaskExecutor extends ExecutorConfigurationSupport
		implements AsyncListenableTaskExecutor, SchedulingTaskExecutor {

    private final Object poolSizeMonitor = new Object();

    private int corePoolSize = 1;

    private int maxPoolSize = Integer.MAX_VALUE;

    private int keepAliveSeconds = 60;

    private int queueCapacity = Integer.MAX_VALUE;

    private boolean allowCoreThreadTimeOut = false;

    private boolean prestartAllCoreThreads = false;

    ...
}
```

위 코드가 Spring이 관리하는 스레드 풀인 ThreadPoolTaskExecutor이다.

해당 클래스의 프로퍼티를 보면,

- `corePoolSize` : 초기 Thread Size는 1

- `maxPoolSize` : 최대 Thread Pool Size는 약 21억

- `queueCapacity` : Queue 용량은 약 21억

으로 설정되어있다. 위 설정을 그대로 사용해도 좋지만 애플리케이션 환경과 서버의 하드웨어 스펙에 따라 조정해 줄 필요는 있을 것 같다.

---

### 다시 돌아와서, 뭐가 문제였나?

- @Asnyc 애노테이션을 활용하여 비동기 메서드를 지정하지 않았던 점

- ThreadPoolTaskExecutor와 같이 스레드 풀을 관리해주는 설정을 Bean으로 등록하지 않은 점

이 두 가지를 적용하지 않았기 때문에 응답에 지연이 생긴 것으로 볼 수 있다.

### 해결 방안 및 성능 개선 결과

```java
@Configuration
@EnableAsync
public class AsyncConfig implements AsyncConfigurer {

    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(3);
        executor.setMaxPoolSize(30);
        executor.setQueueCapacity(90);
        executor.setThreadNamePrefix("SUGO-DIGER-ASYNC-");
        executor.initialize();

        return executor;
    }
}
```

위와 같은 설정을 Bean으로 등록해주고 비동기로 처리할 메서드에 `@Async`애노테이션을 붙여주면 끝이다! 이렇게 간단하게 해결할 수 있음에도 성능 차이는 엄청났다.

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/async/%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0%20%ED%9B%84%20%EB%91%90%EB%B2%88%EC%A7%B8%20%EC%9A%94%EC%B2%AD.jpg?raw=true)

- 응답 시간 `658ms` -> `122ms` 응답 시간이 81% 빨라졌다.

### @Async 애노테이션을 사용할 때 기억해둬야할 것

#### 1. 쓰레드와 큐의 사이즈를 지정할 때 신중해야한다.

여기서 다루는 쓰레드는 `논리적인 쓰레드를`말한다.

쓰레드를 생성하는 비용은 꽤나 엄청난 작업이다. 그렇기 때문에 아래 속성을 정의할 때 주의해야한다.

주로 실제 부하 테스트를 통해 측정해보면 정확하게 지정할 수 있겠으나 나는 그 부분까지는 수행하진 못했다.

아래 속성들은 비동기 처리를 위한 추가적으로 생성할 리소스를 의미한다.

`기본값`은 다음과 같이 설정되어있다.

- `corePoolSize` : 최소 비동기 쓰레드 수 : 1

- `maxPoolSize` : 최대 비동기 쓰레드 수 : 약 21억

- `queueCapacity` : queueCapacity는 작업 큐의 사이즈 : 약 21억

---

#### 1.1. 각 속성이 어떻게 쓰이는 거지?

- 새로운 쓰레드를 생성하는 것은 리소스가 크기 때문에 일반적으로는 쓰레드 풀을 사용한다.
  - `초기 쓰레드 갯수`를 **10**개로 지정했고, `최대 쓰레드 갯수`를 **100**개로 했을 때 **50개의 요청**이 동시에 들어오면 쓰레드 갯수는 몇 개가 될 것인가?
      - 우선 10개로 처리를 한 후 쓰레드가 잡지 못한 요청은 우선적으로 Queue에 쌓인다.

- `큐 사이즈가 꽉차면` 어떻게 될까?
    - 큐 사이즈가 꽉찬다면 큐에 있는 작업을 처리할 쓰레드를 추가로 늘린다.
        - 이 때 쓰레드의 갯수마저도 이전에 지정한 최대치에 도달한다면 그 이후의 요청은 예외가 발생하게 될 것이다.

- 방금 말한 상황에서 발생하는 `예외는 어떻게 처리`해야하는가?
    - 재시도를 통해 서버에 들어온 요청을 책임지고 마쳐야 한다.

- 재시도를 했음에도 `예외가 계속 발생`하면?
    - 그런 상황에서는 요청 값이 잘못되거나 메서드의 로직 자체가 잘못되어있을 가능성이 있을 것이기 때문에 그때는 `비동기 메서드에 대한 검증`을 다시 해봐야한다.

- 큐의 작업을 처리하기 위해 `쓰레드를 늘렸을 때 그 쓰레드들은 계속 유지`되는가?
    - 아니다. `사용되지 않는 쓰레드들은 일정 시간이 지나면 유휴 상태`에 들어가 반납되는 것으로 공식문서에 명시되어있다.

#### 2. @Async가 달린 비동기 메서드는 반환 값이 없어야한다.

당연하게도 비동기로 처리할 로직에는 반환 값이 없어야한다.

반환 값이 있다는 것은 그 모든 리소스를 반환할 때 까지 다음 메서드를 수행하지 못하기 때문에 당연히 비동기 작업에는 반환값이 없어야 하는 것이다.

만약 언젠가 처리가 끝나고나서 그 반환값을 사용하고자 한다면 `CompetableFuture`타입으로 반환해야한다.

#### 3. @Async가 달린 비동기 메서드는 private하면 안된다.

[참고자료 - 왜 @Async 애노테이션이 달린 메서드는 private하면 안되나?](https://dzone.com/articles/effective-advice-on-spring-async-part-1)

@Async 애노테이션은 AOP기반으로 동작한다. 따라서 해당 애노테이션이 붙은 메서드를 감싸는 프록시 객체를 생성하는 것인데

이 프록시 객체는 실제 비동기 작업을 처리할 때 사용된다. 프록시 객체로 동작한다는 것이 그 이유이다.

---

### 비동기로 요청한 내용이 실패했다면 어떻게 되는건가?

지금 로직은 비즈니스 로직을 처리하고 비동기로 외부 서버를 호출한 후 곧바로 리턴하여 클라이언트에게 결과를 전송한다.

그런데 만약 비동기로 외부 서버호출한 내용이 실패한다면 어떻게 되는걸까?

- 재시도를 통해 책임지고 끝낼 수 있도록 한다.
- 예외 처리를 한다.
  - 하지만 이 방법은 아직 잘 모르겠다. 예외처리를 하기 위해선 결국 외부 서버로부터 응답을 받아야하는데, 이 응답을 기다리는 것이 동기로 통신하는 것과 다를 바 없기 때문이다.



---

# SHORTS

## 1. 인덱스를 통해 150만건이 담긴 데이터베이스 내 BETWEEN 조건 질의시 성능 개선

현재 레코드 수는 아래 그림과 같이 약 160만개 이고, 매 1시간마다 800 ~ 1200개의 레코드가 추가되는 테이블을 사용하고 있다.

![img.png](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/index/img.png?raw=true)

위 요구사항을 해결하기 위한 로직을 처리하는데 아래와 같이 12초 ~ 13초의 시간이 소요되어 이를 개선하고자 한다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/dbd5d34f-8329-42dd-b23d-848f96bb9cc0)

### Index를 적용하지 않았을 때의 실행 계획

```mysql
EXPLAIN ANALYZE
SELECT *
FROM news
WHERE created_at BETWEEN '2023-07-07 10:00:00' AND '2023-07-07 11:00:00' AND title LIKE '%입력값%';
```

위와 같은 쿼리를 날렸을 때의 결과는 아래와 같다.

```text
(news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')
(cost=83282.06 rows=26888) (actual time=7404.655..19644.905 rows=2027 loops=1)
-> Table scan on news  (cost=83282.06 rows=242017) (actual time=5.829..19139.414 rows=305977 loops=1)
```

인덱스를 적용하지 않았을 땐 5.8초 ~ 19139.414 초가 걸릴 수 있다.

### Index를 적용한 후 실행 계획

```text
with index condition: (news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')
(cost=2088.81 rows=2027) (actual time=2.678..57.552 rows=2027 loops=1)
```

인덱스를 적용했을 땐 2.678초 ~ 57.552 초가 걸릴 수 있다고 한다.

가장 빠르게 쿼리된 상황에만 보더라도 약 50%가 성능 개선된 것으로 볼 수 있다.

그럼 인덱스를 쓰는게 무작정 좋은 것인지는 조금 더 따져봐야한다.

### Index의 구조

MySQL에서는 B-Tree(Balanced-Tree), HashMap으로 구조화되어있다. DBMS의 종류에 따라 다르겠지만 최근에는 Fractal-Tree과 로그 기반의 Merge-Tree으로 구조화 되는 경우도 있다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/f5eb44b9-6493-4795-90ef-024d42268183)

루트 노드, 브랜치 노드, 리프 노드가 트리 형태로 이어져 있으며 각 노드는 16KB인 페이지다.

리프 노드는 실제 데이터 레코드를 찾아가기 위한 주소를 가지고 있다.

### Index 노드 삽입 과정

저장될 키 값을 이용해 B-Tree에 적절한 삽입점을 검색한다.

저장 위치가 결정되면 레코드의 키 값과 레코드의 주소 정보를 B-Tree의 리프 노드에 저장한다.

리프 노드가 꽉 차서 저장할 수 없을 때는 리프 노드가 분리 되어야 한다. 그리고 이 때 상위 브랜치 노드까지 처리 범위가 넓어진다.

위 이유로 인해 B-Tree는 상대적으로 쓰기 작업(새로운 키 추가)에 비용이 많이 든다.

### 인덱스를 지정할 때 고려해야할 점 - 인덱스의 자격

- 만약 컬럼이 50가지 100가지 등등 많은 데이터를 보유하고 있다면 매 레코드를 추가할 때 마다 해당 컬럼에 대한 인덱스를 모두 추가하는 부가적인 리소스가 발생하게 되어 데이터 삽입이 매우 느리게 될 수 있다.
    - 인덱스의 내부 구현이 LinkedList와 유사한 B-Tree방식으로 구현되어있기 때문이다.
      - 책의 내용이 1000페이지인데 500페이지 쯤에서 내용을 추가해야한다고 해보자
      - 이 상황에선 당연하게도 페이지의 내용을 추가하는 것과 더불어 인덱스를 관리하는 목차 또한 모두 고쳐야한다.
    - 따라서 삽입/변경/삭제 등이 자주 일어나는 테이블에는 적절한 방법이 아니다.

- DBMS에도 인덱스를 관리하기 위한 추가적인 저장공간 리소스가 소모된다.
    - 인덱스는 일반적으로 10% ~ 20%의 공간을 추가로 요구한다.

결론적으로 인덱스는 대용량 테이블에 적용한다면 성능 개선을 기대할 수 있지만

그렇지 않다면 오히려 리소스를 더 사용하고, 조회 성능 까지도 느리게 만들 수 있다.

### 인덱스를 지정할 때 고려해야할 점 - Cardinality

Cardinality, Selectivity 두 용어는 거의 같은 의미로 사용되고, `모든 인덱스 Key 값 중 유니크한 값의 수`를 말한다.

인덱스 키 값 중 중복된 값이 많아지면 많아질수록 Cardinality는 낮아진다.

인덱스는 Cardinality가 높을수록 검색 대상이 줄어들기 때문에 빠른 성능을 나타낼 수 있다.

하지만 Cardinality가 낮더라도 정렬, 그룹화 등을 위해 인덱스를 만드는 것이 더 나을 수도 있다.

인덱스는 항상 검색에만 사용되는 것이 아닌 것을 인지해야한다.

또한 [여러 컬럼을 Index로 지정할 때는 카디널리가 높은 순으로 인덱스를 생성하는 것이 더 효율적이다.](https://jojoldu.tistory.com/243)

---
