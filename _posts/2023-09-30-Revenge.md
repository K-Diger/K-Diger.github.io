---

title: 기본이 중요하다 (프로젝트를 진행하며 고민한 내용의 모든 것)
date: 2023-09-30
categories: [Java, Kotlin, SpringBoot, JPA, QueryDSL, MySQL, Lock, Index, Cache, Async, Test, Authorization]
tags: [Java, Kotlin, SpringBoot, JPA, QueryDSL, MySQL, Index, Cache, Test, Authorization]
layout: post
toc: true
math: true
mermaid: true

---

# SUWIKI

## 1. 강의평가 작성 시 비관적 락을 활용한 동시성 문제를 해결

### 문제 상황

A라는 강의 레코드에 X, Y 가 각각 값을 올리고 내리는 요청이 동시에 발생했다.

레코드의 값을 증가시키기위 위해 SELECT 하는 구문과, 값을 감소시키기 위해 SELECT 하는 구문이 동시에 발생했고

커밋되는 시점이 달라 값을 증가시킨 요청이 커밋되었음에도 값을 감소시키는 요청이 커밋되어 변경사항을 덮어 씌우는 현상이 발생했다.

동시성 문제를 해결하는 방법을 알아보는 중 DBMS에서 충돌이 발생하지 않는 상황을 가정하여 애플리케이션 단위에서 동시성을 처리하는 낙관적 락과 DBMS에서 충돌이 발생하는 상황을 가정하는 비관적 락의 차이를 학습하고 비관적 락을 적용하여 해결하기로 결정했다.

이 방법을 적용하게 된 근거로는 각 방식의 장/단점을 따져보았는데

### 낙관적 락의 장/단점으로는

- 실제로 Lock을 거는 것이 아니기 때문에 성능저하의 우려가 없다.
- 하지만 충돌이 발생해서 롤백을 해야하는 경우 수동으로 해당 데이터의 내용을 모두 롤백하는 로직을 만들어야해서 복잡해질 수 있다.

### 비관적 락의 장/단점으로는

- Lock을 통해 데이터의 무결성을 보장할 수 있다. 그리고 그럼에도 충돌이 발생했을 경우에는 롤백연산을 한 번만 수행해도 된다.
- 하지만 Lock을 거는 것으로 인한 리소스 경쟁으로 성능 저하가 발생할 수 있다.

### 왜 비관적 락을 적용하였는가?

- 실제로 DBMS에서 충돌이 난 것으로인해 데이터 무결성이 깨졌기 때문이다.

### 비관적 락 중 어떤 락을 사용하였는가?

그리고 비관적 락에도 종류가 있는데 특정 레코드에 접근했을 때 다른 트랜잭션에서 읽기만 가능하게 하는 `공유 락`, 읽기 및 쓰기 모두 불가능한 `베타 락`이라는 종류가 있다.

이 차이점을 알아본 후 JPA가 지원하는 `@Lock`애노테이션의 `PessimisticWrite`옵션을 활용했다.

이 옵션은 베타락을 지원하는 것으로 `SELECT FOR UPDATE` 구문을 보낼 수 있도록 하는 옵션이다.

`SELECT FOR UPDATE`는 어떤 트랜잭션이 데이터를 수정하기위해 SELECT를 할 때 다른 트랜잭션에서 접근하지 못하도록 Lock을 거는 쿼리 구문이다.

이 처럼 다른 트랜잭션에서 수정을 위해 접근하지 못하도록 해야하기 때문에 베타락을 사용했다.

참고로, `SELECT FOR UPDATE` 쿼리를 어떤 트랜잭션에서 사용 중이고, 커밋하지 않았다면 다른 트랜잭션에서 `SELECT FOR UPDATE` 구문을 사용할 수 없다.

### 락을 사용하지 않고 이 문제를 해결할 방법은 없었을까?

- 애플리케이션 단위에서 처리하는 낙관적 락을 적용하는 것도 고려해볼만하다고 생각한다.

- 혹은 쿼리를 특정 큐에 쌓아둔 후 순차적으로 처리될 수 있도록 아키텍처적으로 해결해볼만할 것 같다.
  - 큐에 쌓인 쿼리를 POP하면서 처리하게 되면 결국에 병목현상이 일어나는 것 아닌가? 그리고 어떤 쿼리가 오류로 인해 롤백해야한다면 그 시점을 모두 기다려야하지 않나?

### DBMS의 격리수준으로는 어떤 것들이 있나?

- `Read Uncommitted`
  - 커밋, 롤백 여부에 상관없이 다른 트랜잭션에서 읽을 수 있다.
  - `Dirty Read` 현상 발생 (다른 트랜잭션에서 처리한 작업이 완료되지 않았음에도 불구하고 다른 트랜잭션에서 볼 수 있게 되는 현상)

- `Read Committed`
  - 커밋이 완료된 트랜잭션의 변경사항만 다른 트랜잭션에서 읽을 수 있다.
  - `Dirty Read` 현상 해결
  - `NON-REPEATABLE-READ` 현상 발생
    - A 트랜잭션에서 SELECT
    - B 트랜잭션에서 UPDATE 후 커밋
    - A 트랜잭션에서 다시 SELECT
    - 위 상황에서 두 번의 SELECT가 `같은 레코드의 값`을 반환하지 않는다.

- `Repeatable Read`
  - 트랜잭션이 시작되기 전에 커밋된 내용에 관해서만 조회할 수 있다.
  - `NON-REPEATABLE-READ` 현상 해결
  - `Phantom Read` 발생
    - A 트랜잭션에서 SELECT
    - B 트랜잭션에서 INSERT/DELETE 후 커밋
    - A 트랜잭션에서 다시 SELECT
    - 위 상황에서 두 번의 SELECT가 같은 `레코드의 갯수`를 결과를 반환하지 않는다.

- `Serializable`
  - 테이블 내 모든 레코드에 접근 불가능
  - 모든 데이터 부정합 문제 해결

### 비관적 락으로 인해 데이터베이스의 부하 문제가 발생한다면 어떻게 할 것인가?

반복적이거나 자주 변하지 않는 데이터는 직접 DB에 접근하지 않고 캐싱하는 방법을 적용시킬 것 같다.

캐싱은 잘 변하지 않아야한다는 점이 포인트로 알고있는데 자주 변하게되면 캐싱에 반영이 안된 데이터를 읽게되는 데이터 정합성 문제가 발생할 수 있기 때문인 것으로 알고있다.

---

## 2. JWT를 활용한 토큰 기반 인증 vs 세션 기반 인증

### JWT를 활용한 토큰 기반 인증 방식 장/단점

- 장점 1. 확장성과 분산화
  - JWT는 토큰을 생성하고 검증하는 키를 기반으로 동작하며, 토큰에 필요한 정보를 담을 수 있어서 서버 간에 토큰을 공유하거나 전달할 수 있어 확장성이 뛰어나고 분산 환경에서 사용하기 용이하다.

- 장점 2. 상태 없음(Stateless)
  - 서버 측에서 토큰을 검증하고 필요한 정보를 추출하므로, 서버는 클라이언트의 상태를 저장할 필요가 없어 리소스가 절약 될 수 있다.

- 장점 3. 유연한 사용자 권한 관리
  - 토큰 내에 사용자 권한과 관련된 정보를 포함하여 사용자 권한 관리가 용이하며, 토큰의 내용을 이용하여 권한 검사를 수행할 수 있다.

- 단점 1. 토큰 크기와 보안
  - JWT는 탈취될 가능성이 있다. 중요한 정보를 토큰에 포함시키면 보안 문제가 발생할 수 있다.

- 단점 2. 토큰 유효성 검증의 어려움
  - 토큰이 변조되지 않았는지 확인하기 위해 서명을 검증해야 하기 때문에 서명 검증 과정이 추가로 필요하며, 이에 따른 복잡성이 발생할 수 있다.

### 서버 측 세션(Session) 기반 인증 방식 장/단점

- 장점 1. 보안성
  - 세션은 서버에 저장되므로 클라이언트에 노출되지 않는다. 토큰 기반 인증에 비해 보안성이 높다.

- 장점 2. 세션 탈취 시 대처가능
  - 세션을 사용하면 만료 시간을 쉽게 조절하고 조절할 수 있으며, 만료 시간이 지나면 자동으로 세션을 무효화시킬 수 있다.

- 단점 1. 상태 유지
  - 세션은 서버 측에서 상태를 유지해야 하므로, 서버의 메모리를 사용하게 되어 클라이언트가 많을 때 성능 저하가 발생할 수 있다.

- 단점 2. 확장성
  - 분산 환경에서 각 서버마다 발급하는 세션을 관리하기 위해 세션 클러스터를 운영해야하는 복잡성이 증가한다.

### 공격자로부터 클라이언트의 세션이 탈취되었음을 서버측에서는 어떻게 알 수 있을까?

- 클라이언트의 세션 ID가 이전에 없던 위치에서 사용되었거나, 단기간 내에 많은 요청이 발생하는 경우 이상행동으로 간주하여 해당 세션을 무효화한다.

- 클라이언트의 로그인 위치를 기록하고, 동일한 세션 ID가 다른 지역에서 사용되는 경우 해당 세션을 무효화한다.

### 토큰이든 세션이든 탈취될 수 있는 가능성을 최소화하려면 어떻게 해야할까?

- **토큰**은 유효기간을 짧게 가져가고 `Refresh Token`을 적극적으로 사용할 수 있도록 한다.
- 또한 **토큰**의 내용은 암호화를 하여 사용하기 어렵게 하면 좋다. 구체적으로는 해싱을 하는 것이 일반적이다.

- **세션** ID를 암호화 혹은 해싱하여 탈취되었을 때 유효하게 사용하기 어렵게 한다.

---

## 3. 테스트 환경을 개선하여 테스트 코드 작성으로 발생할 생산성 저하 문제 개선

기존에는 테스트 환경이 전혀 마련되어있지 않고 Postman으로 일일히 E2E테스트를 하는게 전부였다.

때문에 실제 프로덕트에서 예상치 못한 버그가 발생한 경우가 조금씩 나오게 되면서 테스트 프레임워크를 활용한 자동화된 테스트 환경을 도입하기로 했다.

그런데, 이미 발생한 버그들을 찾기 위해선 빠르게 테스트 환경을 마련해야할 필요가 있었는데 이 때 통합 테스트를 작성하되 사용자의 행위에 대한 시나리오에 대응할 수 있는 테스트 템플릿을 만들어야겠다고 생각했다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/0bb8bed9-80a2-4478-93dd-b2d78927865c)

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/0deccb5b-eaeb-452b-8b50-44fe7410add1)

위 그림은 해당 테스트 템플릿의 일부이다. 위 SQL 구문을 활용, 테스트 베이스 객체를 상속받으면 통합테스트를 아주 간편하게 작성할 수 있게 된다.

### 테스트 대역의 종류는 무엇이 있을까?

우선 테스트 대역이란, 실제 객체가 아닌 단순한 객체를 이용하여 테스트하는 것을 말한다.

- Mock (행위에 집중하기 위함)
  - Mock (실제 객체의 동작을 모방한 가짜 객체)
    - Mock은 실제 객체를 완전히 대체한다.
    - Spy와 달리 해당 객체의 일부분만을 스텁으로 대체할 수 없다.

  - Spy (실제 객체를 기반으로 생성된 가짜 객체)
    - 실제 메서드가 실행되고 그 메서드가 실제로 테스트된다.
    - 또한 일부분을 스텁으로 대체할 수 있다.

- Stub (상태에 집중하기 위함)
  - Stub (mock객체의 기대 행위(when() ~~ then())를 작성하여 테스트에서 원하는 상황을 작성하는 것을 Stub이라한다.)
  - Dummy (객체가 필요하지만 내부 기능이 필요하지는 않을 때 사용)
  - Fake (실제로 사용된 객체는 아니지만 같은 동작을 하는 구현된 객체이다.(원래 객체의 단순화된 버전))

---

### 테스트 대역이 왜 필요한가?

1. OrderRepository.findOrderList()로 기존 주문서 조회
2. 주문서가 있다면 중복으로 간주해 OrderDuplicateException 발생
3. OrderRepository.createOrder()로 주문서 생성
4. Argument로 넘어온 isNotify가 true이면 NotificationClient.notifyToMobile()를 이용해 알림 발생

위와 같은 OrderService의 createOrder() 비즈니스 로직 시나리오가 있다고 가정했을 때 OrderService의 로직을 테스트하려면 아래 절차가 반드시 필요하다.

- OrderRepository가 사용할 RDB connection 세팅
- RDB에 로직 테스트 조건에 맞는 데이터 세팅
- NotificationClient가 사용할 Notification Server 연결
- Notification이 성공했을 때의 데이터 롤백 처리

이러한 선행 조건이 많아지게 될수록 테스트는 느려지고 복잡도가 증가하게 된다. 또한 외부의 영향으로 로직 자체를 테스트 못하는 경우도 생길 수 있다.

이런 문제 영역을 `메소드의 실제 내부 동작은 실행되지 않고` 상황 설정만 할 수 있도록 해결한 것이 `테스트 대역`이다.

### Mockito를 사용하여 외부 의존성을 제거하여 테스트 작성

```java
public class MockitoTest {
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange
        OrderRepository orderRepository = Mockito.mock(OrderRepository.class);
        NotificationClient notificationClient = Mockito.mock(NotificationClient.class);
        orderService = new OrderService(orderRepository, notificationClient);

        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

### @Mock 애노테이션을 사용하여 Mock 객체 더 쉽게 만들기

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Mock
    private OrderRepository orderRepository;

    @Mock
    private NotificationClient notificationClient;

    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange
        orderService = new OrderService(orderRepository, notificationClient);

        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- 한 가지 주의 할 점은 @ExtendWith(MockitoExtension.class)를 사용해야지만 테스트 시작전 어노테이션을 감지해서 mock 객체를 주입하기 때문에 꼭 함께 사용해야 한다.

- 또한 실제 테스트 대상은 다른 의존성에 대한 Mock 과 달리 Stub을 지정해주지 않았는데 `Mockito의 기본전략`이 `Answers.RETURNS_DEFAULTS`이 이를 해결해준 것이다.
  - 이로 인해 아무런 내용이 없는 메서드가 타입에 맞게 (void) 실행된 것이다.

### @InjectMocks 애노테이션을 사용하여 테스트 대상 Mock 객체에 Mock 의존성 주입하기

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Mock
    private OrderRepository orderRepository;

    @Mock
    private NotificationClient notificationClient;

    @InjectMocks
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("모킹된 레포지토리 실행");
            return Collections.emptyList();
        });

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- @InjectMocks 애노테이션을 활용하면 Arrange 범위에서 의존성을 주입해줄 필요가 없게 된다.

### @Spy 애노테이션을 활용하기

OrderRepository의 메소드 중 createOrder()는 stub하고 findOrderList()는 실제 기능을 그대로 사용하고 싶을 때 `Spy`를 사용하면 좋다.

Spy는 Mock과 달리 객체의 전체를 대체하는 것이 아닌 일부분만 대체하여 사용하는 것이 가능하다.

```java
@ExtendWith(MockitoExtension.class)
public class MockitoTest {

    @Spy
    private OrderRepository orderRepository;

    @Spy
    private NotificationClient notificationClient;

    @InjectMocks
    private OrderService orderService;

    @Test
    public void createOrderTest() {
        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("Spy 객체로, OrderRepository의 CreateOrder 메서드를 Stub으로 대체한다.");
            return null;
        }).when(orderRepository).createOrder();

        // Arrange - Stub
        Mockito.doAnswer(invocation -> {
            System.out.println("모킹된 푸쉬 알림 클라 실행");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- 이렇게 특정 객체의 특정 메서드만 스텁으로 대체해서 사용하고 싶다면, Spy를 쓸 수 있고, 스텁으로 대체하지 않은 메서드는 실제 메서드로 사용된다.

### @MockBean 애노테이션 활용하기 (@SpringBootTest)

```java
@SpringBootTest
class BasicSpringTests {

    @Autowired
    private OrderService orderService;

    @Test
    void createOrderTest() {
        orderService.createOrder(true);
    }
}
```

위 코드는 실제 모든 빈과 Ioc/DI 컨테이너를 다 띄우고 테스트한다. 따라서 테스트 대역을 사용하지 않았을 때의 문제점을 모두 안고가는 테스트이다.

이 과정을 더 단축시키기 위해 @MockBean 애노테이션이 쓰인다. 이 애노테이션은 컨테이너에 실제 객체가 아닌 Mock객체를 등록하게한다.

```java
@SpringBootTest
class BasicSpringTests {

    @MockBean
    private OrderRepository orderRepository;

    @MockBean
    private NotificationClient notificationClient;

    @Autowired
    private OrderService orderService;

    @Test
    void createOrderTest() {
        // Arrange - Stub
        Mockito.when(orderRepository.findOrderList()).then(invocation -> {
            System.out.println("MockBean 애노테이션으로 만들어진 OrderRepository를 사용한다.");
            return Collcetions.emptyList();
        });
        // Arrange - Stub
        Mockito.doAnsewr(invocation -> {
            System.out.println("MockBean 애노테이션으로 만들어진 NotificationClient를 사용한다.");
            return null;
        }).when(notificationClient).notifyToMobile();

        // Act
        orderService.createOrder(true);

        // Assert
        Mockito.verify(orderRepository, Mockito.times(1)).createOrder();
        Mockito.verify(notificationClient, Mockito.times(1)).notifyToMobile();
    }
}
```

- `@Mock` 애노테이션이 달린 객체는 `@InjectMocks`에 주입된다.
- `@MockBean` 애노테이션이 달린 객체는 `@SpringBootTest`에 주입된다.

---

## 3. Caffeine Cache를 활용하여 홈 API 응답시간 개선

### 왜 홈 API에 캐시를 적용했는가?

캐싱의 대상은 자주 변하지 않고 조회 요청이 빈번하게 일어나는 데이터가 적절하다.

홈 API가 보여주는 데이터는 빈번하게 변경되지 않지만 사용자들이 가장 많이 조회하는 API이기 때문에 캐싱을 적용하기로 판단했다.

### 캐싱된 데이터가 가장 최신의 데이터라는 것을 판별할 수 있는 방법은?

서버에서 캐시가 업데이트될 때마다 캐시의 버전을 업데이트하고 클라이언트는 요청할 때 버전을 함께 전달하도록 한다.

서버는 현재 버전과 클라이언트가 전달한 버전을 비교하여 최신인지 확인하여 데이터의 최신화 여부를 판별하면 될 것 같다.

### 왜 Caffeine Cache를 적용했는지?

- 캐시 전략에 우선순위를 부여 가능하다.
- 캐시 히트율이 매우 높은 알고리즘인 `Window TinyLFU`를 제공한다.

### Caffeine 캐싱 데이터 저장 방식

- JVM Heap 메모리 내에 저장된다.

### Caffeine 캐싱 전략

Caffeine의 캐싱 전략을 살펴보자

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84pKiujtGOpbnpVgIwhpkQ.png)

- `Main Cache`가 존재하며 전체 용량의 99%를 가지고 있다. (Segmented LRU)
    - `Main Cache`의 20%를 차지하는 `Probation Cache`가 존재한다.
        - 새로운 데이터가 `Probataion`영역에 저장되어야 할 때, `Probation`영역의 데이터와 LRU로 비교하여 `Evict`를 수행한다.
            - `Probation` 영역에 일정 횟수 이상 접근되면 `Protected Cache`로 옮겨진다.(LFU)
    - `Main Cache`의 80%를 차지하는 `Protected Cache`가 존재하며 이 공간의 데이터는 제거되지 않는다.
        - `Protected Cache`영역이 꽉차면 오래된 데이터는 쫓겨난다.(LRU)
        - 이 때 쫓겨난 데이터는 `TinyLFU` 알고리즘에 의해 제거되거나 `Main Cache`의 `Probation Cache` 영역으로 옮겨진다.

- `Window Cache`가 존재하여 전체 용량의 1%를 가지고 있다.
    - 새로운 데이터가 쓰일 때 가장 먼저 이 공간에 쓰인다.
    - `Window Cache`가 꽉차있다면 `LRU`로 비교하여 기존 데이터를 쫓아낸다. (제거되는 게 아님)
        - 이 쫓아내진 데이터는 `Tiny LFU` 알고리즘으로 `Probation Cache`와 비교하여 `Probation Cache`에 저장되거나 승격하지 못하면 제거된다.

여기서 사용되는 `TinyLFU`의 정책을 살펴보기 전 우선 용어 정리는 다음과 같다.

- `Window Cache`, `Main Cache내의 Protected Cache`로부터 제거되는 데이터는 `Candidate`이다.
- `Main Cache 내의 Probation Cache`에서 제거되는 데이터는 `Victim`이다.

`TinyLFU`의 정책은 아래와 같다.

- `Candidate Cache` 접근 횟수 > `Victim Cahce` 접근 횟수 -> `Victim 제거`
- `Candidate Cache` 접근 횟수 < `Victim Cahce` 접근 횟수 && `Candidate` 접근 횟수가 5회 미만 -> `Candidate 제거`
- 둘 중 하나 `랜덤하게 제거`

정리하자면 `Window TinyLFU` 알고리즘은

- `Window Cache`에 있는 새로운 데이터가 `Probation` 영역으로 승격시킬 지 제거할 지 판단할 때 사용하는 알고리즘이다.
    - 승격하지 못하면 제거된다.

- `Protected Cache`의 용량이 꽉 찼을 때 `Probation` 영역에서 승격될 대상과 비교할 때 사용하는 알고리즘이다.
    - 여기서 기존 `Protected Cache`의 데이터는 제거되거나 `Probation` 영역으로 강등된다.

---

### Local Cache - Ehcache vs Caffeine 성능 비교

[벤치마크 결과](https://github.com/ben-manes/caffeine/wiki/Benchmarks)

위 벤치마크 결과를 본다면 압도적으로 카페인 캐시가 성능이 좋게 나온다.

성능이 좋다고 무조건 쓰는게 좋은 것은 아니므로 기존 환경을 잘 고려하여 선택하면 될 것 같다.

### 성능 개선 측정은 어떻게 했는지?

포스트맨으로 측정했다. 최근에 JMeter, nGrinder등 성능 측정, 모니터링 툴을 알게되어 이러한 도구들을 쓸 수도 있을 것 같다.

### 캐시가 효과가 있는지는 어떻게 아는지?

```java
@Component
@RequiredArgsConstructor
@Slf4j
public class CacheStaticsLogger {

    private final CacheManager cacheManager;

    public void getCachesStats(String cacheKeys) {
        CaffeineCache cache = (CaffeineCache) cacheManager.getCache(cacheKeys);
        CacheStats stats = Objects.requireNonNull(cache).getNativeCache().stats();

        log.info("Cache hit count: " + stats.hitCount());
        log.info("Cache miss count: " + stats.missCount());
    }
}
```

위와 같은 CacheStats 객체를 통해 캐시 히트와 캐시 미스의 대한 지표를 얻을 수 있다.

이 객체를 활용, 로그를 모니터링을 함으로써 캐시가 히트됐을 때의 응답속도를 측정하면 근거가 될 것으로 본다.

### 캐시의 TTL은 어떻게 지정할까?

캐시 히트율을 통계로 추출하여 캐시 TTL을 조정해가며 적절한 타협점을 찾는게 좋을 것 같다.

### 캐시 TTL을 짧게 가져갔을 때와 길게 가져갔을 때의 장/단점은 어떤게 있을까?

- `TTL을 짧게 가져간다면`
  - 캐싱된 데이터가 가장 최근에 업데이트된 데이터에 빠르게 반영될 수 있는 장점이 있다.
  - 하지만 자주 변하지 않는 데이터라면 캐시를 교체하는 리소스가 빈번하게 발생할 수 있다는 단점이 있다.

- `TTL을 길게 가져간다면`
  - 캐시를 교체하는 주기가 길어지기 때문에 캐싱된 데이터를 변경없이 오랫동안 제공할 수 있는 장점이 있다.
  - 하지만 캐시가 교체되어야할 시점에 적절하게 교체되지 못하여 변경 전의 데이터를 장기간 제공하는 상황이 발생할 수 있다는 단점이 있따.

### 해당 캐시가 가장 최신의 데이터임을 판별하는 방법은?

캐시에 `메타데이터`를 넣으면 어떨까?

- 캐시 데이터에 해당 캐시의 버전을 표기할 수 있는 메타데이터를 통해 클라이언트와 버전 싱크를 맞추면 해결할 수 있을 것으로 생각한다.

- 클라이언트는 응답 받은 데이터의 캐시 정보에 대한 메타데이터를 확인하고 이전에 받은 데이터의 버전과 일치한다면 최신 버전으로 간주하고
  - 만약 버전이 변경되었다면 새로운 캐시를 받아 반영하는 방식을 적용한다면 될 것 같다.

---

# SUGO

## 1. @Async 애노테이션을 사용하여 81% 성능 개선

### 문제 상황

클라이언트에 푸쉬 알림을 전송하기 위해 FCM 서버에 요청하는 로직을 추가했더니 아래와 같이 658ms가 소요되는 현상이 발생했다.

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/async/%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0%20%EC%9D%B4%EC%A0%84%20%EB%91%90%EB%B2%88%EC%A7%B8%20%EC%9A%94%EC%B2%AD.jpg?raw=true)

이 메서드를 추가하기 전에는 100ms도 넘지 않았던 응답시간이 저렇게 급격하게 늘어나니 클라이언트단에서도 응답을 기다리느라 사용자 경험을 해치는 상황이 발생하게 되었다.

### 어떻게 속도를 빠르게 할 수 있을까?

외부 서버를 호출하는 로직을 비동기로 처리하면 어떨까? 굳이 외부 서버로 던진 요청이 완료된 것을 확인받은 후에 다른 비즈니스 로직을 처리해야할까? 를 고민하다가 직접 비동기 메서드를 적용해보기로 했다.

### ThreadPoolTaskExecutor와 @Async

[Asynchronous calls in spring](https://www.linkedin.com/pulse/asynchronous-calls-spring-boot-using-async-annotation-omar-ismail/)

Spring에서 비동기 작업을 처리하려면 다음 두 가지를 관리해야한다.

- @Asnyc 애노테이션으로 비동기 메서드를 지정한다.
- 비동기 메서드의 처리를 담당하는 스레드 풀을 관리해줘야한다.

스레드 풀을 관리하기 위한 Bean을 등록하기 위해서는 아래의 인터페이스의 구현체를 셋팅해줘야 한다.

```java
public interface AsyncConfigurer {

	@Nullable
	default Executor getAsyncExecutor() {
		return null;
	}

	@Nullable
	default AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
		return null;
	}

}
```

하지만 꼭 위 인터페이스를 구현체로 등록하지 않아도 되긴하다. 그냥 ThreadPoolTaskExecutor를 반환하는 메서드를 Bean으로 등록해주면 되는 것일 뿐이다.

### @Async 애노테이션이 어떻게 동작하는건가?

- @Async 애노테이션이 붙은 메서드가 실행될 때, 프록시가 해당 호출을 가로채고 Task Executor에 전달한다.

- Task Executor는 새로운 스레드를 생성하고 해당 스레드에서 호출된 로직을 실행한다. 그리고 이 때 이 메서드의 리턴을 기다리지 않고 다른 작업을 계속 수행한다.

- 이전에 호출시킨 메서드가 리턴되었다면 Task Executor에 결과를 반환한다.

이 때 새로운 스레드를 생성한다는 점이 성능 저하의 문제가 될 수 있다.

```java
public class ThreadPoolTaskExecutor extends ExecutorConfigurationSupport
		implements AsyncListenableTaskExecutor, SchedulingTaskExecutor {

    private final Object poolSizeMonitor = new Object();

    private int corePoolSize = 1;

    private int maxPoolSize = Integer.MAX_VALUE;

    private int keepAliveSeconds = 60;

    private int queueCapacity = Integer.MAX_VALUE;

    private boolean allowCoreThreadTimeOut = false;

    private boolean prestartAllCoreThreads = false;

    ...
}
```

위 코드가 Spring이 관리하는 스레드 풀인 ThreadPoolTaskExecutor이다.

해당 클래스의 프로퍼티를 보면,

- `corePoolSize` : 초기 Thread Size는 1

- `maxPoolSize` : 최대 Thread Pool Size는 약 21억

- `queueCapacity` : Queue 용량은 약 21억

으로 설정되어있다. 위 설정을 그대로 사용해도 좋지만 애플리케이션 환경과 서버의 하드웨어 스펙에 따라 조정해 줄 필요는 있을 것 같다.

---

### 다시 돌아와서, 뭐가 문제였나?

- @Asnyc 애노테이션을 활용하여 비동기 메서드를 지정하지 않았던 점

- ThreadPoolTaskExecutor와 같이 스레드 풀을 관리해주는 설정을 Bean으로 등록하지 않은 점

이 두 가지를 적용하지 않았기 때문에 응답에 지연이 생긴 것으로 볼 수 있다.

### 해결 방안 및 성능 개선 결과

```java
@Configuration
@EnableAsync
public class AsyncConfig implements AsyncConfigurer {

    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(3);
        executor.setMaxPoolSize(30);
        executor.setQueueCapacity(90);
        executor.setThreadNamePrefix("SUGO-DIGER-ASYNC-");
        executor.initialize();

        return executor;
    }
}
```

위와 같은 설정을 Bean으로 등록해주고 비동기로 처리할 메서드에 `@Async`애노테이션을 붙여주면 끝이다! 이렇게 간단하게 해결할 수 있음에도 성능 차이는 엄청났다.

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/async/%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0%20%ED%9B%84%20%EB%91%90%EB%B2%88%EC%A7%B8%20%EC%9A%94%EC%B2%AD.jpg?raw=true)

- 응답 시간 `658ms` -> `122ms` 응답 시간이 81% 빨라졌다.

### @Async 애노테이션을 사용할 때 기억해둬야할 것

#### 1. 쓰레드와 큐의 사이즈를 지정할 때 신중해야한다.

여기서 다루는 쓰레드는 `논리적인 쓰레드를`말한다.

쓰레드를 생성하는 비용은 꽤나 엄청난 작업이다. 그렇기 때문에 아래 속성을 정의할 때 주의해야한다.

주로 실제 부하 테스트를 통해 측정해보면 정확하게 지정할 수 있겠으나 나는 그 부분까지는 수행하진 못했다.

아래 속성들은 비동기 처리를 위한 추가적으로 생성할 리소스를 의미한다.

`기본값`은 다음과 같이 설정되어있다.

- `corePoolSize` : 최소 비동기 쓰레드 수 : 1

- `maxPoolSize` : 최대 비동기 쓰레드 수 : 약 21억

- `queueCapacity` : queueCapacity는 작업 큐의 사이즈 : 약 21억

---

#### 1.1. 각 속성이 어떻게 쓰이는 거지?

- 새로운 쓰레드를 생성하는 것은 리소스가 크기 때문에 일반적으로는 쓰레드 풀을 사용한다.
  - `초기 쓰레드 갯수`를 **10개**로 지정했고, `최대 쓰레드 갯수`를 **100개**로 했을 때 **50개의 요청이 동시에** 들어오면 쓰레드 갯수는 몇 개가 될 것인가?
      - 우선 10개로 처리를 한 후 쓰레드가 잡지 못한 요청은 우선적으로 Queue에 쌓인다.

- `큐 사이즈가 꽉차면` 어떻게 될까?
    - 큐 사이즈가 꽉찬다면 큐에 있는 작업을 처리할 쓰레드를 추가로 늘린다.
        - 이 때 쓰레드의 갯수마저도 이전에 지정한 최대치에 도달한다면 그 이후의 요청은 예외가 발생하게 될 것이다.

- 방금 말한 상황에서 발생하는 `예외는 어떻게 처리`해야하는가?
    - 재시도를 통해 서버에 들어온 요청을 책임지고 마쳐야 한다.

- 재시도를 했음에도 `예외가 계속 발생`하면?
    - 그런 상황에서는 요청 값이 잘못되거나 메서드의 로직 자체가 잘못되어있을 가능성이 있을 것이기 때문에 그때는 `비동기 메서드에 대한 검증`을 다시 해봐야한다.

- 큐의 작업을 처리하기 위해 `쓰레드를 늘렸을 때 그 쓰레드들은 계속 유지`되는가?
    - 아니다. `사용되지 않는 쓰레드들은 일정 시간이 지나면 유휴 상태`에 들어가 반납되는 것으로 공식문서에 명시되어있다.

#### 2. @Async가 달린 비동기 메서드는 반환 값이 없어야한다.

당연하게도 비동기로 처리할 로직에는 반환 값이 없어야한다.

반환 값이 있다는 것은 그 모든 리소스를 반환할 때 까지 다음 메서드를 수행하지 못하기 때문에 당연히 비동기 작업에는 반환값이 없어야 하는 것이다.

만약 언젠가 처리가 끝나고나서 그 반환값을 사용하고자 한다면 `CompetableFuture`타입으로 반환해야한다.

#### 3. @Async가 달린 비동기 메서드는 private하면 안된다.

[참고자료 - 왜 @Async 애노테이션이 달린 메서드는 private하면 안되나?](https://dzone.com/articles/effective-advice-on-spring-async-part-1)

@Async 애노테이션은 AOP기반으로 동작한다. 따라서 해당 애노테이션이 붙은 메서드를 감싸는 프록시 객체를 생성하는 것인데

이 프록시 객체는 실제 비동기 작업을 처리할 때 사용된다. 프록시 객체로 동작한다는 것이 그 이유이다.

---

### 비동기로 요청한 내용이 실패했다면 어떻게 되는건가?

지금 로직은 비즈니스 로직을 처리하고 비동기로 외부 서버를 호출한 후 곧바로 리턴하여 클라이언트에게 결과를 전송한다.

그런데 만약 비동기로 외부 서버호출한 내용이 실패한다면 어떻게 되는걸까?

- 재시도를 통해 책임지고 끝낼 수 있도록 한다.
- 예외 처리를 한다.
  - 하지만 이 방법은 아직 잘 모르겠다. 예외처리를 하기 위해선 결국 외부 서버로부터 응답을 받아야하는데, 이 응답을 기다리는 것이 동기로 통신하는 것과 다를 바 없기 때문이다.

---

# SHORTS

## 1. 인덱스를 통해 150만건이 담긴 데이터베이스 내 BETWEEN 조건 질의시 성능 개선

현재 레코드 수는 아래 그림과 같이 약 150만개 이고, 매 1시간마다 800 ~ 1200개의 레코드가 추가되는 테이블을 사용하고 있다.

![img.png](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/index/img.png?raw=true)

위 요구사항을 해결하기 위한 로직을 처리하는데 아래와 같이 12초 ~ 13초의 시간이 소요되어 이를 개선하고자 한다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/dbd5d34f-8329-42dd-b23d-848f96bb9cc0)

### Index를 적용하지 않았을 때의 실행 계획

```mysql
EXPLAIN ANALYZE
SELECT *
FROM news
WHERE created_at BETWEEN '2023-07-07 10:00:00' AND '2023-07-07 11:00:00' AND title LIKE '%입력값%';
```

위와 같은 쿼리를 날렸을 때의 결과는 아래와 같다.

```text
Table scan on news: (news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')
(cost=83282.06 rows=242017) (actual time=5.829..19139.414 rows=305977 loops=1)
```

인덱스를 적용하지 않았을 땐 5.8초 ~ 19139.414 초가 걸릴 수 있다.

### Index를 적용한 후 실행 계획

```text
with index condition: (news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')
(cost=2088.81 rows=2027) (actual time=2.678..57.552 rows=2027 loops=1)
```

인덱스를 적용했을 땐 2.678초 ~ 57.552 초가 걸릴 수 있다고 한다.

가장 빠르게 쿼리된 상황에만 보더라도 약 50%가 성능 개선된 것으로 볼 수 있다.

그럼 인덱스를 쓰는게 무작정 좋은 것인지는 조금 더 따져봐야한다.

### Index의 구조

MySQL에서는 B-Tree(Balanced-Tree), HashMap으로 구조화되어있다. DBMS의 종류에 따라 다르겠지만 최근에는 Fractal-Tree과 로그 기반의 Merge-Tree으로 구조화 되는 경우도 있다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/f5eb44b9-6493-4795-90ef-024d42268183)

루트 노드, 브랜치 노드, 리프 노드가 트리 형태로 이어져 있으며 각 노드는 16KB인 페이지다.

리프 노드는 실제 데이터 레코드를 찾아가기 위한 주소를 가지고 있다.

### Index 노드 삽입 과정

저장될 키 값을 이용해 B-Tree에 적절한 삽입점을 검색한다.

저장 위치가 결정되면 레코드의 키 값과 레코드의 주소 정보를 B-Tree의 리프 노드에 저장한다.

리프 노드가 꽉 차서 저장할 수 없을 때는 리프 노드가 분리 되어야 한다. 그리고 이 때 상위 브랜치 노드까지 처리 범위가 넓어진다.

위 이유로 인해 B-Tree는 상대적으로 쓰기 작업(새로운 키 추가)에 비용이 많이 든다.

### 인덱스를 지정할 때 고려해야할 점 - 인덱스의 자격

- 만약 컬럼이 50가지 100가지 등등 많은 데이터를 보유하고 있다면 매 레코드를 추가할 때 마다 해당 컬럼에 대한 인덱스를 모두 추가하는 부가적인 리소스가 발생하게 되어 데이터 삽입이 매우 느리게 될 수 있다.
    - 인덱스의 내부 구현이 LinkedList와 유사한 B-Tree방식으로 구현되어있기 때문이다.
      - 책의 내용이 1000페이지인데 500페이지 쯤에서 내용을 추가해야한다고 해보자
      - 이 상황에선 당연하게도 페이지의 내용을 추가하는 것과 더불어 인덱스를 관리하는 목차 또한 모두 고쳐야한다.
    - 따라서 삽입/변경/삭제 등이 자주 일어나는 테이블에는 적절한 방법이 아니다.

- DBMS에도 인덱스를 관리하기 위한 추가적인 저장공간 리소스가 소모된다.
    - 인덱스는 일반적으로 10% ~ 20%의 공간을 추가로 요구한다.

결론적으로 인덱스는 대용량 테이블에 적용한다면 성능 개선을 기대할 수 있지만

그렇지 않다면 오히려 리소스를 더 사용하고, 조회 성능 까지도 느리게 만들 수 있다.

### 인덱스를 지정할 때 고려해야할 점 - Cardinality

Cardinality, Selectivity 두 용어는 거의 같은 의미로 사용되고, `모든 인덱스 Key 값 중 유니크한 값의 수`를 말한다.

인덱스 키 값 중 중복된 값이 많아지면 많아질수록 Cardinality는 낮아진다.

인덱스는 Cardinality가 높을수록 검색 대상이 줄어들기 때문에 빠른 성능을 나타낼 수 있다.

하지만 Cardinality가 낮더라도 정렬, 그룹화 등을 위해 인덱스를 만드는 것이 더 나을 수도 있다.

인덱스는 항상 검색에만 사용되는 것이 아닌 것을 인지해야한다.

또한 [여러 컬럼을 Index로 지정할 때는 카디널리가 높은 순으로 인덱스를 생성하는 것이 더 효율적이다.](https://jojoldu.tistory.com/243)

## 2. 다량의 데이터 삽입 시 JdbcTemplate을 활용한 데이터베이스 커넥션 부족 문제 해결

### 구체적으로 어떻게 해결했는가?

기존 로직은 크롤링을 통해 얻은 데이터의 갯수만큼 반복문을 순회하며 쿼리를 보내는 로직이였다.

매 크롤링마다 약 800개에서 1500개까지 데이터가 추가되는데 현재 로직에 따르면 매 크롤링 주기마다 커넥션을 800개에서 1500개를 맺고 끊는 과정이 필요했던 것이다.

어떤 시기에 데이터가 삽입되지 않은 것을 확인해보니 DB 커넥션이 부족해서 모든 트랜잭션에 롤백되었다는 에러 메세지를 서버에서 확인할 수 있었다.

이 문제를 해결하기 위해서 Slow Query로 인해 어떤 트랜잭션에서 커넥션을 오래 사용할만한 부분을 찾아냈고, 커넥션을 최소화하여 데이터를 삽입할 수 있는 방법을 알아보기 시작했다.

### 벌크 삽입

기존 로직은 커넥션을 데이터의 갯수만큼 맺고 끊는다고 했다.

이를 한 커넥션에서 해결할 수 있는 방법이 벌크 삽입이라고 알게되어 실제 코드로 적용하는 방법을 알아보기 시작했다.

### 벌크 삽입 Spring Data JPA - saveAll()

`saveAll()` 메서드의 구현 부분을 보면 트랜잭션은 하나로 가져가되 그 내부에서 반복문을 통해 다수의 데이터를 삽입하는 로직으로 구성되어있다.

즉, 벌크 삽입과는 다른 결의 삽입 연산자이다.

실제로 테스트를 통해 반복문 내부에 `save()`메서드를 호출하는 것과 `saveAll()`메서드를 호출하는 것을 측정했을 때

`save()`메서드는 6134ms

`saveAll()`메서드는 4736ms가 소요되었다.

로직을 수행하는 시간 자체가 줄었으나 완전한 방법은 아니라고 생각했다.

### 벌크 삽입 JdbcTemplate

`saveAll()` 메서드는 JPA Hibernate가 만들어주는 쿼리를 사용하기 때문에 결국에 부가적인 작업이 더 필요하다.

따라서 직접 벌크 삽입을 쿼리할 수 있는 방법을 찾아보니 JdbcTemplate이 있다는 것을 알게 되었다.

JdbcTemplate으로 똑같은 환경에서 똑같은 데이터를 삽입하는 과정을 측정해보니 2952ms가 측정되었다.

위에서 보았던 `saveAll()`메서드에 비해서도 상당히 성능이 개선되었다.

하지만 여기서 문제점이 있었다. JPA를 사용하지 않기 때문에 영속성에 해당되지 않기 때문에 JPA가 매핑하는 AutoIncrement가 적용된 PK를 인식하지 못하는 현상이 발생했다.

따라서 AutoIncrement될 것으로 생각하여 PK를 제외한 값을 넣고 Save Insert를 하면 id는 null 값이 들어간 상태가 된다.

이 문제를 해결하기 위해 직접 PK를 다루는 부가적인 로직이 추가되었다.

1. 데이터 삽입 전 현재 DB에 있는 가장 마지막 인덱스를 뽑아온다.
2. 데이터를 삽입 후 가장 마지막의 인덱스를 뽑아온다.
3. 1번과 2번의 사이에 해당하는 모든 수를 추출하여 Wrapper Entity에서 보관하고 사용한다.

### 이 데이터를 벌크 삽입으로 했을 때 문제점은 없는가?

- 트랜잭션 자체의 크기가 커지기 때문에 작업이 중간에 실패하면 데이터의 무결성이 깨질 수 있다.
  - 롤백 시에도 많은 시간이 소요될 수 있다.
- 트랜잭션의 크기 자체가 크기 때문에 커넥션을 오래 가지고 있는다는 문제점이있다.

### 벌크 삽입의 문제점을 어떻게 해결할 수 있을까?

- 삽입할 데이터를 더 작은 단위들로 분할하여 삽입하도록 한다.
  - 이렇게 하면 트랜잭션 크기가 줄어들기 때문에 롤백과 커넥션에 대한 문제점이 어느정도 완화될 수 있다.
  - 만약 순서까지 보장해야한다면 해당 로직 자체를 특정 Queue에 순서에 맞게 삽입한 후 Pop하면서 쪼개진 삽입 연산을 수행할 것 같다.

---

## 3. AOP, ThreadLocal을 활용하여 사용자 인증/인가 로직 간소화

### 왜 이런 과정이 필요했는지?

기존 코드에는 특정 API 컨트롤러마다 사용자 인증 정보를 가져오는 로직이 반복되고있었다.

컨트롤러에서 이에 대한 관심사를 해결하는 것 보다는 이를 분리하는게 더 역할에 맞다고 생각해서 이를 분리하기로 했다.

### 구체적으로 어떻게 구현한건지?

HTTP Connection을 맺고 있는 Thread의 ThreadLocal에 서버에서 직접 발급하고 데이터베이스에서 관리하는 사용자의 UUID를 등록된 인증 정보를 보관하도록 하고

이 인증 정보를 사용할 수 있는 로직을 전역적으로 선언하여 Spring 내부의 계층에서 자유롭게 사용할 수 있는 로직을 작성했다.

그리고 이 로직을 사용할 수 있는 대상을 애노테이션으로 지정할 수 있게 하여 반복되어 등장하는 사용자 인증 정보를 꺼내는 로직을 제거했다.

### 사용자는 그러면 어떻게 자신의 UUID를 가지고 있는가?

클라이언트의 로컬 스토리지나 내부 DB에 저장하여 매 요청마다 인증 헤더에 실어 보내야한다.

### 해당 UUID가 탈취되었을 때의 문제점과 해결방안은?

DB에서 탈취된 것으로 판단된 UUID를 제거하여 피해를 막는 사후조치를 해야할 것 같다.

### 이 과정 자체가 그러면 토큰 기반 방식의 인증 방법일까? 세션 기반 방식의 인증 방법일까?

세션 기반 인증 방식으로 볼 수 있을 것 같다.

#### 근거

사용자의 UUID를 서버에서 직접 발급하고 서버 내부에서 관리하는 것이므로 세션 기반 인증 방식에 가깝다고 할 수 있을 것 같다.

하지만 서버 내부의 메모리에서 해당 인증 정보를 관리하는 것이 아닌 DB에 저장되어있는 내용을 관리하는 것이기 때문에 완전한 세션방식이라고 하기엔 조금 어려울 수도 있을 것 같다.

세션 기반 인증에서는 서버 측에서 세션을 관리하고, 클라이언트에게 세션 ID를 부여하여 이를 사용자 식별에 활용한다.

### 공격자로부터 클라이언트의 인증 정보가 탈취되었음을 서버측에서는 어떻게 알 수 있을까?

- 클라이언트의 UUID가 이전에 없던 위치에서 사용되었거나, 단기간 내에 많은 요청이 발생하는 경우 이상행동으로 간주하여 해당 세션을 무효화한다.

- 클라이언트의 로그인 위치를 기록하고, 동일한 UUID가 다른 지역에서 사용되는 경우 해당 세션을 무효화한다.

### 토큰 기반 인증 방식 장/단점

- 장점 1. 확장성과 분산화
    - JWT는 토큰을 생성하고 검증하는 키를 기반으로 동작하며, 토큰에 필요한 정보를 담을 수 있어서 서버 간에 토큰을 공유하거나 전달할 수 있어 확장성이 뛰어나고 분산 환경에서 사용하기 용이하다.

- 장점 2. 상태 없음(Stateless)
    - 서버 측에서 토큰을 검증하고 필요한 정보를 추출하므로, 서버는 클라이언트의 상태를 저장할 필요가 없어 리소스가 절약 될 수 있다.

- 장점 3. 유연한 사용자 권한 관리
    - 토큰 내에 사용자 권한과 관련된 정보를 포함하여 사용자 권한 관리가 용이하며, 토큰의 내용을 이용하여 권한 검사를 수행할 수 있다.

- 단점 1. 토큰 크기와 보안
    - JWT는 탈취될 가능성이 있다. 중요한 정보를 토큰에 포함시키면 보안 문제가 발생할 수 있다.

- 단점 2. 토큰 유효성 검증의 어려움
    - 토큰이 변조되지 않았는지 확인하기 위해 서명을 검증해야 하기 때문에 서명 검증 과정이 추가로 필요하며, 이에 따른 복잡성이 발생할 수 있다.

### 서버 측 세션(Session) 기반 인증 방식 장/단점

- 장점 1. 보안성
    - 세션은 서버에 저장되므로 클라이언트에 노출되지 않는다. 토큰 기반 인증에 비해 보안성이 높다.

- 장점 2. 세션 탈취 시 대처가능
    - 세션을 사용하면 만료 시간을 쉽게 조절하고 조절할 수 있으며, 만료 시간이 지나면 자동으로 세션을 무효화시킬 수 있다.

- 단점 1. 상태 유지
    - 세션은 서버 측에서 상태를 유지해야 하므로, 서버의 메모리를 사용하게 되어 클라이언트가 많을 때 성능 저하가 발생할 수 있다.

- 단점 2. 확장성
    - 분산 환경에서 각 서버마다 발급하는 세션을 관리하기 위해 세션 클러스터를 운영해야하는 복잡성이 증가한다.

## 4. GC 튜닝 (JVM의 구조와 GC의 동작 원리)

### 참고자료

[Catsbi's Blog](https://catsbi.oopy.io/3ddf4078-55f0-4fde-9d51-907613a44c0d)

[Gmarket Tech Blog](https://dev.gmarket.com/62)

[Jdk-17 Specification](https://blogs.oracle.com/javamagazine/post/java-jdk-17-generally-available)

[JDK-17 GC Tuning Guide](https://docs.oracle.com/en/java/javase/17/gctuning/ergonomics.html#GUID-DA88B6A6-AF89-4423-95A6-BBCBD9FAE781)

[DZone](https://dzone.com/articles/jvm-architecture-explained)

---

### JVM 이란?

Java Code 나 Application 을 실행시키기 위한 런타임 환경을 제공해주는 엔진이다.

Java 코드를 .class파일(ByteCode)로 변환해준다.

JVM은 Java Runtime Environment(JRE)의 일부이다.

다른 언어의 컴파일러와는 다르게, Java 컴파일러는 JVM 이 인식할 수 있는 코드를 생성해낸다.

---

### JVM 기능

- Java 코드를 ByteCode 로 변환한다. (변환된 ByteCode는 인터프리팅 된다.)
- JVM은 메모리 공간 할당을 담당한다.
- Java Code <-> JVM <-> System

### Java 코드가 실행되는 플로우

Class Loader -> Byte Code Verifier -> Execution Engine

---

### JVM 구조

![JVM: Architecture](https://techvidvan.com/tutorials/wp-content/uploads/sites/2/2020/06/JVM-Model.jpg)

크게 분류하자면 `Class Loader`, `Runtime Data Areas`, `Execution Engine`으로 나눌 수 있다.

각 요소가 어떤 역할을 하는지 알아보자

---

### Class Loader

![Class Loader](https://javatutorial.net/wp-content/uploads/2017/11/jvm-featured-image.png)

클래스 파일을 로딩하기 위한 하위 시스템이다.

Class Loader는 세 가지 주요 기능이 있다.

- `Loading`
- `Linking`,
- `Initialization`

---

#### Class Loader - Loading

클래스 로더는 .class 파일을 읽고, 바이너리 데이터를 생성하여 메소드 영역에 저장한다.

클래스 로더의 종류로는 세 가지가 있으며 각 역할이 부여되어있다.

- `BootStrap` : 시스템 클래스 및 Java 표준 라이브러리에 대한 클래스를 로딩한다. (jre/lib 폴더의 rt.jar에 위치한 클래스들을 로딩한다.)
- `Extension Class Loader` : jre/lib/ext 폴더 내의 클래스를 로딩한다.
- `Application Class Loader` : 작성한 코드에 대한 클래스, 환경 변수를 로딩한다.

또한 각 .class 파일 마다 JVM은 아래의 세 가지 정보를 `메서드 영역에 저장`한다.

1. `로드된 클래스`와 그 모든 `연관 부모 클래스`

2. .class 파일이 `Class` or `Interface` or `Enum`어떤 것으로 작성된 것인지?

3. `수정자`, `변수`와 `메서드 정보` 등

우리는 흔히 `getClass()`메서드로 class를 코드 관점에서도 사용이 가능하다. 클래스 로더가 하는 역할이 덕분인데,

.class 를 로딩을 마친 후에, JVM 은 `Heap 영역에 이 파일들을 나타내기 위해` Class 유형의 객체를 생성한다.

---

#### Class Loader - Linking

`Verification`, `Preparation`, `Resolution` 을 수행한다.

##### Class Loader - Linking : Verification

.class 파일이 올바른 형식으로 지정되고, 유효한 컴파일러에 의해 생성되었는지 확인한다.

확인에 실패 했을 때 `RuntimeException` 혹은 `java.lang.VerifyError` 가 발생한다.

이 과정이 끝났다면, 클래스 파일을 컴파일 할 준비가 완료 된 것이다.

##### Class Loader - Linking : Preparation

클래스 변수에 메모리를 할당하고 메모리를 기본값으로 초기화한다.

##### Class Loader - Linking : Resolution

간접 참조 방식을 직접 참조 방식으로 바꾸는 과정이다. 참조된 엔티티를 찾기 위하여 `메서드 영역을 검색`한다.

---

### Class Loader - Initialization

모든 static 변수가 코드 및 static block 에 정의된 값으로 할당된다. (static 키워드가 들어간 요소들 메모리 할당)

부모에서 자식 순으로 수행된다.

--> static 요소들 메모리 할당 --> 부모 클래스 메모리 할당 --> 자식 클래스 메모리 할당 --> 기타 요소들 할당

---

### Runtime Data Area

#### Method Area

`클래스 구조(클래스 이름, 부모 클래스 이름, 메서드 및 변수 정보)` 등 클래스 수준의 모든 정보를 담고 있다.

`static 변수`를 가지고 있다.

JVM 당 하나의 메서드 영역을 가지고 있고, `공유 될 수 있는` 영역이다.

---

#### Heap

모든 `객체 및 연관된 인스턴스 변수/배열`이 저장되는 장소이다.

이 공간은 `공유될 수` 있으며 추후 `GC 의 대상`이 되는 동적인 영역이다.

Heap 영역은 조금 더 깊게 들어가면 다음 도식화 같이 구성되어있다.

![Java 7 vs Java 8 Heap](https://miro.medium.com/v2/resize:fit:513/0*rKZvTnuUkEc5LoXW.jpg)

위 그림으로 대강 틀을 잡고 아래 그림과 설명을 보면 이해가 쉬웠다.

![](https://itzsrv.com/static/55998773d3933af1327d3560a71ff975/083f8/jvm-mem.png)

##### Heap - Young Generation (새로운 객체가 할당되는 공간)

- Young Generation은 새로운 객체들이 할당되는 영역이다.
- Eden 영역과 두 개의 Survivor 영역(S0, S1)으로 구성된다.
- 새로운 객체들은 Eden 영역에 할당된다.

#### Heap Young Generation - Eden

- 새로운 객체가 할당되는 초기 영역이다.
- Eden 영역에 있는 객체들 중 일부는 살아남아서 Survivor 영역으로 이동한다.

#### Heap Young Generation - Survivor (S0, S1)

- Eden 영역에서 일정 기간 동안 살아남은 객체들 중 일부가 여기로 이동한다.
- 이동한 객체들 중 살아남은 객체는 다음 번 GC 사이클에서 다른 Survivor 영역으로 이동한다.
- 여러 번의 이동을 거치면서 살아남은 객체들은 Old Generation으로 이동할 수 있다.

#### Heap - Old Generation (오랫동안 유지되는 객체가 할당되는 공간)

- Old Generation은 Young Generation에서 오랫동안 살아남은 객체들이 할당되는 공간이다.
- Old Generation 영역에 있는 객체들은 장기간 메모리를 점유하게 되며, 가비지 컬렉션 시에 주요 대상이 된다.

---

### Threads Area(Stack Area)

JVM은 `모든 쓰레드`에, `각 하나의 런타임 스택`을 제공한다.

각 스택의 모든 블럭은 `메서드 호출`이 발생하면 이를 `스택에 저장`하고 `지역 변수`가 이곳에 저장되며 `공유 가능`한 영역이다

---

### PC Register

스레드가 `현재 실행중인 JVM 명령의 주소`를 저장한다. `각 스레드 별로 별도의 PC 레지스터`가 있다.

---

#### Native Internal Threads (Native Method Stacks)

Java 가 아닌 다른 언어(C, C++)로 작성된 Native Code 의 명령을 저장한다.

---

### Runtime Area 요약

#### Method 영역 (공유 가능)
1. static 키워드로 선언된 요소들
2. 클래스 이름, 부모클래스, 클래스 메서드, 클래스 변수 등

#### Heap (공유 가능)
1. 인스턴스
2. 인스턴스 변수

GC가 참조 되지 않은 메모리를 확인하고 제거하는 영역

#### Thread (Stack) (공유 가능)
1. 메서드 내에서 사용되는 값들을 저장(매개변수, 메서드에서 선언한 변수, 리턴값 등)
2. 지역변수(메서드에 의한 변수)

---

### Execution Engine

`JIT Compiler` 와 `GC`가 존재하는 영역으로 Native Code (타 언어로 만들어진 메서드 등)을 다루는 영역이다.

실행 엔진은 .class 파일을 실행시켜준다.

또한 byte 코드를 각 행마다 읽어들이며(인터프리터에 의해) 메모리 공간에 존재하는 데이터와 정보들을 이용하며 명령어를 실행시켜준다.

실행 엔진은 `세 부분으로 분류` 할 수 있다.

#### Execution Engine - Interpreter

바이트 코드를 한줄 씩 해석한 다음 실행한다.

인터프리터의 단점으로는, `하나의 메서드를 여러 번` 호출 할 경우, `매 번 해석`을 해줘야 하는 것으로 CPU, Memory를 더 잡아먹게 된다.

#### Execution Engine - Just-In-Time Compiler(JIT)

인터프리터의 효율을 증가시키기 위해 사용된다.

`전체 바이트 코드를 컴파일`하여 `네이티브 코드(기계어)`로 변경하므로 인터프리터가 반복되는 메서드 호출을 하지 않아도

JIT 에서 해당 부분에 관한 네이티브 코드를 제공하므로

재 해석이 필요하지 않아 효율을 증가 시켜주는 방법이다.

---

### JIT Compiler 란

JAVA의 성능을 증대시키기 위한 런타임 환경의 컴파일러이다.

런타임 중 바이트 코드를 기계어로 컴파일해준다.

[IBM Documentation](https://www.ibm.com/docs/en/ztpf/1.1.0.15?topic=reference-jit-compiler)

[Oracle Documentation](https://docs.oracle.com/javase/specs/jvms/se8/html/index.html)

---

### JIT Compiler 개요

JAVA 프로그램은 다양한 컴퓨터 구조(OS) 에서 JVM 이 인터프리팅 할 수 있는 바이트 코드를 가진 클래스로 구성된다.

런타임 환경에서, JVM 은 클래스 파일(바이트 코드)을 로드하고, 각 개별 바이트 코드의 의미를 결정하고 적절한 계산을 수행한다.

즉, JIT 컴파일러는 런타임 때 바이트코드를 기계 코드로 컴파일하여 JAVA 프로그램의 성능을 개선하는데 도움이 된다.

#### 그럼 어떤걸 기계 코드로 바꾸나?

우선 인터프리터와 JIT 컴파일러의 존재와 역할을 알아야한다.

인터프리터 : Java Code -> Bytes Code

JIT 컴파일러 : Bytes Code -> Machine Code

JVM은 바이트 코드를 실행시킬 수 있는 `인터프리터`가 존재한다.

그런데 여기서 자주 사용되는 명령어가 있다고 했을 때 이 바이트 코드로 이루어진 명령어를 매번 기계어로 해석하는 인터프리팅 작업이 반복된다면 성능은 분명 좋지 않을 것이다.

그래서 JIT 컴파일러가 등장했다. 자주 사용되는 명령어로 판단 된다면 `JIT 컴파일러`가 기계어로 변환한다.

---

### JIT Compiler 조금 더 알기

#### 조금 더 알기 1

JIT 컴파일러는 기본값으로 무조건 동작하도록 셋팅 되어져있다.

어떤 메서드가 컴파일 되어있다고 했을 때, 그 컴파일 된 메서드를 호출하면

해당 메서드 내용을 ByteCode 로 변환하는 컴파일 과정을 거치지 않고 컴파일된 메서드(기계어)를 바로 호출한다.

컴파일 된 메서드를 호출하면 프로세서와 메모리의 사용을 요구하지 않아 성능이 좋아진다.

#### 조금 더 알기 2

JIT 컴파일러가 첫 컴파일을 수행할 때는 프로세서 + 메모리를 필요로 한다.

JVM 이 처음 시작될 때 수 천개의 메서드가 호출되기 때문에 처음 시작에는 시작 시간이 늦어질 수 있다.

#### 조금 더 알기 3

실제로 모든 메서드가 처음 호출 된다고해서 컴파일 되는게 아니다. 각 메서드에 대해 JVM은 `Count`를 설정한다. 그리고 `메서드가 호출될 때마다` `Count를 감소`시켜 호출 횟수를 관리한다.

`Count가 0`에 도달하면 메서드에 관한 `JIT 컴파일이 시작`된다. 따라서 `자주 사용하는 메서드`는 `JVM의 시작 이후에 바로 컴파일`되고 `덜 사용하는 메서드`는 훨씬 `나중에 컴파일 되거나 컴파일 되지 않는다.`

이 Count(임계값) 은 Application 시작 시간과 장기적인 성능 측면에서의 균형을 유지하기 위해 채택된 방법이다.

---

### JIT 컴파일 - 최적화

JIT 컴파일러는 각 메서드를 다른 최적화 단계를 부여하여 컴파일한다.

#### 최적화 단계

`Cold`, `Warm`, `Hot`, `VeryHot`, `Scorching`

최적화 수준이 뜨거울수록(Scorching 단계와 가까워질수록) 더 높은 성능을 제공하지만 컴파일 비용이 더 많이 들게 된다.

메서드의 `기본 최적화 단계`는 `Warm` 이지만, JIT가 시작 시간을 개선하기 위해 `Cold 단계로 다운그레이드 하기도 한다.`

다른 매커니즘을 통해 메서드를 더 최적화 하여 컴파일 할 수도 있다.

hot, veryHot, scorching 단계의 메서드들이 그 대상이다.

JIT 컴파일러는 비활성화 할 수 있지만 JIT의 문제 진단을 위한 경우 등을 제외하곤 권장되진 않는다.

---

### JIT 컴파일러가 코드를 최적화 하는 방법

#### JIT 컴파일러에게 학습 시킬 것

컴파일을 위한 메서드가 선택되면, `JVM은 JIT`에게 바이트 코드를 전달한다. `JIT`는 바이트코드의 문장을 정확하게 이해할 수 있어야 한다.

그래서 JIT가 메서드를 분석하는데 도움이 되도록 `바이트 코드`는, `기계 코드와 더 유사한 Tree`라는 내부 표현으로 `재구성`된다.

그 후 Trees 가 기계어로 번역이 된다. `BytesCode -> Trees -> MachineCode`

#### JIT 컴파일러 성능 증대

JIT 컴파일러는 `여러 개의 컴파일 스레드`를 이용하여 컴파일 작업을 수행할 수 있다.

JIT `컴파일 스레드`는 시스템에서 `사용되지 않고 있는 코어가 있을 경우에만` 성능 향상을 제공한다.

---

### JIT 컴파일 과정 (최적화 과정)

#### 1단계 : Inlining

인라인 작업은, A 라는 메서드가 있을 때 이 메서드를 B라는 더 큰(더 자주 사용하는) 메서드나 클래스가 사용한다면

B가 담겨있는 트리에 A 라는 메서드를 병합하는 것이다.

이렇게하면 자주 실행되는 메서드의 호출 속도가 빨라지게 된다.

##### 인라인 정책

1. Trivial inlining
2. Call graph inlining
3. Tail recursion elimination
4. Virtual call guard optimizations

#### 2단계 : Local Optimizations

로컬 최적화는 고전적인 컴파일러의 기능을 수행하여 최적화를 한다.

##### 최적화 과정

1. 로컬 데이터 흐름 분석과 최적화
2. 레지스터를 사용하여 최적화
3. Java 문법 간소화

#### 3단계 : Control Flow Optimizations

메서드 내부의 흐름을 분석하고, 코드를 재 정렬한다.

##### 흐름 제어 과정

1. 코드 재정렬, 분할 및 제거
2. 루프 감소 및 반전
3. 루프 스트라이딩 및 루프 불변 코드 모션
4. 루프 풀기 및 필링
5. 루프 버전 관리 및 전문화
6. 예외 지향 최적화
7. 스위치 분석

#### 4단계 : Global Optimizations

1. 전체 메서드를 대상으로 수행된다. 컴파일 시간이 길어 비용이 크지만 성능을 크게 향상시킬 수 있는 과정이다.
2. 전역 최적화
3. 글로벌 데이터 흐름 분석 및 최적화
4. 부분적 중복 제거
5. 탈출 분석
6. GC 및 메모리 할당 최적화
7. 동기화 최적화

#### 5단계 : Native Code Generation

기계어 생성!

---

#### Execution Engine - Garbage Collector

참조되지 않은 객체를 정리해준다.

### Garbage Collector란?

Java 프로그램에서, 자동으로 메모리를 관리해주는 과정이다.

C/C++ 와 달리, 프로그래머는 객체의 메모리 할당과 해제를 신경 쓸 필요가 없다.

Garbage Collector 이 데몬 쓰레드의 형태로 수행해주기 때문이다.

---

### Garbage Collector 동작 배경

Java 코드는 JVM 에 의해 ByteCode로 컴파일된다. Java 프로그램이 JVM 에서 실행될 때 객체는 Heap에 저장되고

일부 객체들은 더 이상 힙에 존재할 필요가 없어질 때가 오게 된다. 이때 Garbage Collector가 사용되지 않는 객체들을 찾아 제거한다.

---

### Garbage Collector 동작 과정

Garbage Collector 은 Heap 영역을 살펴보고 사용 중인 객체와 사용하지 않는 객체를 식별한다.

이 중 사용하지 않는 객체에 해당되는 요소들은 삭제한다.

사용 중인 객체는 포인터가 유지되고 있지만

사용 중이지 않은 객체는 어떤 부분에서도 포인터가 존재하지 않는다.

Garbage Collector 은 JVM 이 구현한다.

---

### Garbage Collector 의 동작 유형

#### JVM 힙 영역의 구분

![](https://www.programmersought.com/images/220/8462f4bfba5f173585f6f8cd2dce12ac.JPEG)

##### Young Generation

새로 생성된 객체는 Young Generation 에서 시작한다.

모든 객체가 시작되는 1개의 Eden 공간과

Garbage Collector Cycle 에서 살아남은 후

Eden 공간에서 살아남은 객체들이 이동하는 공간인 2개의 Survivor 공간이 있다.

##### Old Generation

수명이 긴 객체는 결국 Young Generation 에서 Old Generation 으로 이동된다.

Old Generation 에서 Garbage Collected 가 되었을 때, 가장 우선순위가 높게 처리되는 공간이다.

##### Permanent Generation (Metaspace)

클래스 및 메서드와 같은 메타데이터가 저장되는 장소이다.

추가적으로, `Java 8 에 들어오면서, Permanent Generation 이 사라지고 Metaspace 영역이 생겼다.`

`Permanent Generation` 은 `JVM 에 의해서 Heap 영역의 메모리 크기가 강제되던 영역`이였다.

하지만 `Metaspace 가 Native 메모리 영역`에 배치되면서, `운영체제가 자동으로 그 크기를 조절`할 수 있게 되고, `Heap 에서 사용할 수 있는 메모리의 크기가 늘어나게 됐다.`

---

### GC 상태

#### Minor/Incremental

Young Generation 에서 객체가 제거 되었다는 것을 말하는 유형이다.

#### Major/Full

Minor Garbage Collector 에서 살아남은 객체를 Old 로 옮긴다.

Old 에서는 GC 대상이 덜 자주 발생하게 된다.

---

### Garbage Collector 에 관한 주요 개념

#### Unreachable Objects - 도달 할 수 없는 객체

객체에 관한 참조가 포함되어 있지 않으면 객체에 도달 할 수 없다 라고 한다.

```java
public class Main {
    public static void main(String[] args) {
        Integer i = new Integer(4);
        // the new Integer object is reachable  via the reference in 'i'

        i = null;
        // the Integer object is no longer reachable.
    }
}
```

위 코드를 보면, Integer 4를 대입했을 때는, 참조가 가능하지만

null 을 할당한 순간, 메모리를 참조할 수 없기 때문에 Unreachable 하다고 보는 것이다.

## Eligibility for Garbage Collector - GC 자격

위 코드를 보면, Integer 4를 위한 공간을 할당해 줬지만

i = null 이라는 구문 이후 에는 그 공간이 쓸모 없게 되는 것이다.

따라서 이 공간에 관하여 GC에 적합하다고 한다.

## GC 대상으로 만드는 방법

1. 참조 변수를 Null 할당이 가능하도록 한다.
2. 참조 변수를 재할당 한다.
3. 메서드 내에 객체를 생성한다.
4. Isolation Island 를 활용한다.

GC 대상이 될 수 있는 객체를 만들었다 하더라도, 즉시 GC 에 의해 제거되진 않는다. JVM이 GC를 실행시킬 때 객체가 소멸된다.

---

## JVM 에 GC 를 실행시키도록 하는 방법

1. `System.gc()` 메서드를 사용하여 JVM 에 GC 를 실행하도록 하는 Static 메서드를 실행 시킨다.
2. `Runtime.getRuntime().gc()` 메서드를 사용하여 GC 를 요청할 수 있다.

또한 `System.gc()` 는 `Runtime.getRuntime().gc()` 와 사실상 동일한 요청이다.

---

## GC 의 이점

Heap 영역에서 참조되지 않은 객체를 제거하기 때문에 메모리 효율성을 높일 수 있다. JVM 의 일부분인 GC 가 자동으로 수행되기 때문에 프로그래머의 추가 작업이 필요하지 않다.

---

## Java 코드로 GC 실행시키는 방법

### 일반적인 JAVA CODE (GC 실행 X)

```java
    class Employee {

    private int ID;
    private String name;
    private int age;
    private static int nextId = 1;
    // it is made static because it
    // is keep common among all and
    // shared by all objects

    public Employee(String name, int age) {
        this.name = name;
        this.age = age;
        this.ID = nextId++;
    }

    public void show() {
        System.out.println("Id=" + ID + "\nName=" + name
            + "\nAge=" + age);
    }

    public void showNextId() {
        System.out.println("Next employee id will be="
            + nextId);
    }
}

class UseEmployee {
    public static void main(String[] args) {
        Employee E = new Employee("GFG1", 56);
        Employee F = new Employee("GFG2", 45);
        Employee G = new Employee("GFG3", 25);
        E.show();
        F.show();
        G.show();
        E.showNextId();
        F.showNextId();
        G.showNextId();

        { // It is sub block to keep
            // all those interns.
            Employee X = new Employee("GFG4", 23);
            Employee Y = new Employee("GFG5", 21);
            X.show();
            Y.show();
            X.showNextId();
            Y.showNextId();
        }
        // After countering this brace, X and Y
        // will be removed.Therefore,
        // now it should show nextId as 4.

        // Output of this line
        E.showNextId();
        // should be 4 but it will give 6 as output.
    }
}
```

### GC 실행 JAVA CODE

```java
    class Employee {

    private int ID;
    private String name;
    private int age;
    private static int nextId = 1;

    // it is made static because it
    // is keep common among all and
    // shared by all objects
    public Employee(String name, int age) {
        this.name = name;
        this.age = age;
        this.ID = nextId++;
    }

    public void show() {
        System.out.println("Id=" + ID + "\nName=" + name
            + "\nAge=" + age);
    }

    public void showNextId() {
        System.out.println("Next employee id will be="
            + nextId);
    }

    protected void finalize() {
        --nextId;
        // In this case,
        // gc will call finalize()
        // for 2 times for 2 objects.
    }
}

public class UseEmployee {
    public static void main(String[] args) {
        Employee E = new Employee("GFG1", 56);
        Employee F = new Employee("GFG2", 45);
        Employee G = new Employee("GFG3", 25);
        E.show();
        F.show();
        G.show();
        E.showNextId();
        F.showNextId();
        G.showNextId();

        {
            // It is sub block to keep
            // all those interns.
            Employee X = new Employee("GFG4", 23);
            Employee Y = new Employee("GFG5", 21);
            X.show();
            Y.show();
            X.showNextId();
            Y.showNextId();

            //GC
            X = Y = null;
            System.gc();
            System.runFinalization();
            //GC
        }
        E.showNextId();
    }
}
```

## GC 진행 단계 - Minor Collection

힙 영역 중 Young Generation에 속한 객체를 제거한다.

오라클 공식문서에 따르면 Young Generation에는 죽은 객체들이 많기 때문에 비교적 빠르게 수행된다고 한다.

즉, Stop-The-Wolrd의 지속시간이 짧다는 의미이다.

일반적으로 이 GC 단계에서 살아남은 객체들은 Old Generation으로 이동된다.

## GC 진행 단계 - Major Collection

힙 영역 중 Old Generation에 속한 객체를 제거한다.

Old Generation의 용량이 가득 차면 수행되는 GC단계로, 전체 힙을 대상으로 GC를 수행한다. 따라서 Stop-The-World의 지속시간이 상대적으로 길게 동작한다.

## GC 성능 고려 사항

### 전체 Heap의 용량

GC의 처리량은 사용 가능한 메모리에 반 비례한다.

할당된 메모리가 크면 Heap 영역자체가 꽉 차는 주기가 늘어나기 때문에 GC가 동작하는 주기 자체도 늘어나기 때문이다.

기본적으로 Heap이 할당되는 비율은 다음과 같다.

- -XX:MaxHeapFreeRatio (default value is 70%)
- -XX:MinHeapFreeRatio (default value is 40%)

여기서 사용되는 메모리의 비율은 시스템 전체의 메모리를 나타내는 것이 아닌 JVM에 할당된 메모리를 가리킨다.

### Young Generation의 크기

`-XX:NewRatio=3`와 같은 옵션을 사용하면 Young Generation과 Old Generation의 비율이 1:3이라는 것을 의미한다.

즉, eden 공간과 Survivor 공간을 합친 크기는 전체 힙 크기의 1/4이 된다.

Young Generation의 크기에 따라 GC 성능이 달라질 수 있다.

Young Generation의 크기가 클 수록 Minor Collection이 덜 자주 발생한다. 하지만 정적 크기의 Heap용량을 부여했을 때 Young Generation의 크기가 큰 만큼 Old Generation의 크기가 작아지는 것을 의미하므로

Major Collcetion이 자주 발생할 수 있다. 따라서 최적의 선택을 하기 위해선 객체의 수명을 분석해야한다.

### Survivor Space의 크기

`-XX:SurvivorRatio`옵션으로 Survivor의 크기를 지정할 수 있다.

이 공간의 크기가 너무 작으면 Old Generation으로 오버플로우가 발생할 수 있고

이 공간의 크기가 너무 크다면 쓸데없이 비어있게 되어 낭비될 수 있다.

따라서 JVM은 객체가 오래되기 전에 복사할 수 있는 횟수인 임계값 수를 선택한다.

`-Xlog:gc,age`옵션으로 이 임계값과 Young Generation의 객체들의 수명을 표시할 수 있다.

# 튜닝할 시 고려해아할 점 요약

### Young Generation

- 먼저 JVM에 제공할 수 있는 최대 힙 크기를 결정한다.
    - 그런 다음 최적의 설정을 찾기 위해 Young Generation 규모에 대한 성능 지표를 구성한다.

- 과도한 페이지 오류 및 스래싱을 방지하려면 최대 힙 크기는 항상 시스템에 설치된 메모리 양보다 작아야한다.

- 총 힙 크기가 고정된 경우 Young Generation 크기를 늘리려면 Old Generation 크기를 줄여야 한다.
    - 특정 시간에 애플리케이션에서 사용하는 모든 라이브 데이터와 일정량의 여유 공간(10~20% 이상)을 보유할 수 있을 만큼 이전 세대를 충분히 크게 유지해야한다.

### Old Generation

- 되도록 Yong Generation에 많은 공간을 할당하는 것이 좋다.

---

# GC종류

## GC - Serial Collector

Serial Collector는 단일 스레드를 사용하여 모든 가비지 수집 작업을 수행하여 스레드 간 통신 오버헤드가 없기 때문에 상대적으로 효율적이다.

다중 프로세서 하드웨어를 활용할 수 없기 때문에 단일 프로세서 시스템에 가장 적합하며 특정 하드웨어 및 운영 체제 구성에서 기본적으로 선택되거나 `-XX:+UseSerialGC`옵션을 사용하여 명시적으로 활성화할 수 있다.

---

## GC - Parallel Collector (JDK 6)

Parallel Collector는 Throughput Collector 라고도 하며 Serial Collctor와 유사하다.

Serial Collector와 Parallel Collector의 주요 차이점은 Parallel Collector에는 가비지 수집 속도를 높이는 데 사용되는 여러 스레드가 있다는 것이다.

Parallel Collector는 다중 프로세서 또는 다중 스레드 하드웨어에서 실행되는 중대형 데이터 세트가 있는 애플리케이션을 위한 것으로 `-XX:+UseParallelGC.`옵션을 사용하여 활성화할 수 있다.

병렬 압축은 Parallel Collector가 Major Collection을 병렬로 수행할 수 있도록 하는 기능이다. 병렬 압축이 없으면 Major Collection이 단일 스레드를 사용하여 수행되므로 확장성이 크게 제한될 수 있다.

`-XX:+UseParallelGC`지정된 경우 병렬 압축이 기본적으로 활성화되고 `-XX:-UseParallelOldGC`옵션을 사용하여 병렬 압축을 비활성화할 수 있다.

### Parallel GC의 스레드 수를 지정하기



---

## GC - Garbage-First (G1) Garbage Collector (JDK 11)

G1은 동시 수집기이다. 동시 수집기는 애플리케이션에 대해 비용이 많이 드는 일부 작업을 동시에 수행한다. 이로 인해 높은 처리량을 달성할 수 있다.

G1 GC는 소형 시스템에서 대량의 메모리를 갖춘 대형 멀티프로세서 시스템으로 확장하도록 설계되었으며, Stop-The-World의 지속 시간을 단축시켰다.

G1은 대부분의 하드웨어 및 운영 체제 구성에서 기본적으로 선택되거나 `-XX:+UseG1GC`를 사용하여 명시적으로 활성화할 수 있다.

---

### GC - ZGC (JDK 15)

ZGC(Z Garbage Collector)는 Stop-The-World가 가장 짧은 확장 가능한 Garbage Collector가다.

ZGC는 애플리케이션 스레드 실행을 중단하지 않고 비용이 많이 드는 모든 작업을 동시에 수행한다.

ZGC는 몇 밀리초의 Stop-The-World을 가지지만 이로 인해 일부 처리량이 희생됩니다. 적은 시간의 Stop-The-World 필요한 애플리케이션을 위한 것입니다.

Stop-The-World 지속시간은 사용 중인 힙 크기와 무관하며. ZGC는 8MB에서 16TB까지의 힙 크기를 지원한다. `-XX:+UseZGC`

---

# JVM 튜닝 - 문제 상황

프로젝트를 진행하면서 크롤러를 돌리는 중 아래와 같은 에러가 뜨고 있었다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/181f8d12-d4b9-4479-9c82-c4f64ee3231a)

크롤링하면서 OOM이 터졌다는 것 같은데 왜 터진지 알아보자..

# 서버 스펙

기존 서버 스펙은 NCP의 Compact옵션인 (CPU: 2CORE, Memory : 2GB)를 사용하고 있었다.

서버 내 Java 버전은 OpenJDK 17버전을 사용하는 것으로 아무런 튜닝 옵션을 주지 않고 애플리케이션을 실행하고 있었기 때문에 다음과 같은 JVM 스펙이 동작하고 있었다.

[JDK 17](https://docs.oracle.com/javase/specs/jvms/se17/html/jvms-2.html)

![image](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/768fd0fa-5052-48fc-acc6-d70a99a8bc5d)

현재 나의 서버에서 구동되는 JVM 정보는 위 그림과 같다. (위 사진은 최근 스펙업을 한 2CORE, 4GB Memory로 대체하였다.)

기본값으로 구동되는 옵션의 기준은 아래 링크에 설명되어있다.

[Oracle Docs](https://www.oracle.com/java/technologies/ergonomics5.html)

- 초기 힙 크기 : 물리적 메모리의 1/64 --> 8.388608MB

- 최대 힙 크기 : 물리적 메모리의 1/4 --> 1GB

여튼 기본값을 지정된 초기 힙 크기를 가지고 크롤러를 돌릴 때 문제가 발생한다고 하니까 이를 해결해보자.

# 서버, JVM 튜닝

우선 JVM의 절대적인 Heap 공간이 모자라다는 것이 문제다. 모니터링을 통해 내린 결론은 크롤러가 요구하는 Memory Size는 약 2GB 언저리이다.

따라서 애플리케이션 코드를 더 최적화 하지 않는 이상 최대 메모리를 2GB로 돌리는 것은 불가능할 것이다.

## 서버의 수직적 확장

서버의 스펙을 올린다. 기본 2Core 2GB Memory에서 2Core 4GB Memory로 스펙을 올렸다.

## JVM 튜닝

서버 스펙을 올려 메모리를 넉넉하게 발급했음에도 불구하고 아래와 같은 에러가 뜨고있었다.

```text
Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "http-nio-8081-Poller"
Exception in thread "HikariPool-1 housekeeper" java.lang.OutOfMemoryError: Java heap space
Exception in thread "Catalina-utility-2" java.lang.OutOfMemoryError: Java heap space
```

여전히 Heap 공간이 모자라다고 투정을 부리고 있는 것인데, 이 역시 JVM의 기본 값으로 Heap 사이즈를 설정했기 때문에 그 사이즈로도 감당이 안된다는 것인데

스펙업을 통해 남는 메모리를 조금 더 할당하도록 튜닝해야한다.

### 튜닝 명령어 - Heap Size 설정, GC 지정

```shell
java -Xms256m -Xmx2048m -XX:+UseParallelGC
```

위 명령어는 JVM 옵션을 커스텀하여 실행하도록 하는 것이다.

- **-Xms256m**은 최소 힙 사이즈를 나타내는 것으로 256M를 지정했다.

- **-Xmx2048m**은 최대 힙 사이즈를 나타내는 것으로 2048M(2GB)를 지정했다.

- **-XX:+UseParallelGC**은 GC를 지정해 주는 것인데, ParallelGC를 지정했다.

## GC 선택에 대한 결론

GC 종류를 알아봤으니 그 다음으로 어떤 GC가 어떨 때 적합한지 정리된 글을 보자면

- 애플리케이션에 다소 엄격한 Stop-The-Wolrd에 대한 요구 사항이 있는 경우가 아니면 먼저 애플리케이션을 실행하고 VM이 수집기를 선택하도록 허용해라.

- 필요한 경우 힙 크기를 조정하여 성능을 향상시켜라.
    - 성능이 여전히 목표를 충족하지 못하는 경우 GC를 직접 선택해라.

- **소규모 애플리케이션**일 경우에는(최대 약 100MB) **Serial GC**를 선택해라. (-XX:+UseSerialGC)
    - 애플리케이션이 **단일 프로세서**에서 실행되고 **Stop-The-World에 대한 제약이 없는 경우** **Serial GC**를 선택해라.

- 애플리케이션 **성능이 첫 번째 우선 순위**이고 **Stop-The-World에 대한 요구 사항이 없거나 1초 이상의 일시 중지가 허용**되는 경우 **기본 값**으로 지정된 GC를 사용하거나 **Parallel GC**를 선택해라. (-XX:+UseParallelGC)

- **응답 시간이 전체 처리량보다 중요**하고 **Stop-The-World 시간이 약 1초 미만**으로 유지해야 하는 경우는 **G1 GC or CMS GC**를 사용해라. (-XX:+UseG1GC or -XX:+UseConcMarkSweepGC)

위 결론에 따라서 나는 Parallel GC를 선택했다. 시간당 한 번씩 로직을 수행하기 때문에 Stop-The-World에 대한 제약사항은 우선순위가 가장 낮으나 애플리케이션 자체의 성능을 극대화 하는게 더 우선이기 때문이다.

메모리 부족이 발생한 상황을 다시 돌아보면 초기 서버에는 괜찮았지만 시간이 지날 수록 쓰레기값들이 누적되면서 메모리가 터져버린 것으로 예상되었다.

따라서 아래와 같은 명령어를 서버 시스템 내의 crontab으로 설정하여 Cache Memory를 정리해 주는 방법을 추가했다.

```shell
0 * * * * sync && echo 3 > /proc/sys/vm/drop_caches
```
