---

title: 성능 개선의 근본 - 캐시
date: 2023-08-15
categories: [Cache]
tags: [Cache]
layout: post
toc: true
math: true
mermaid: true

---

# Cache

`캐싱`은 사실 컴퓨터 구조 수업을 들을때도 배우는 개념이다. 그 만큼 컴퓨터 환경에서의 가장 근본적인 성능 개선의 방법 중 하나이다.

애플리케이션 관점에서도 똑같다. DB와 통신하는 작업 혹은 저장소에 접근하는 작업은 당연하게도 비용이 크게 측정된다. 애플리케이션 내부에서 처리하는 것이 아닌 외부와 통신하는 과정이기 때문이다.

그래서 자주 쓰이고 자주 변하지 않는 데이터는 캐싱을 통해 DB조회 빈도를 줄이는 캐싱을 적용한다면 성능 개선을 이뤄낼 수 있다.

---

# Local Cache | Global Cache

캐싱의 방법은 크게 두 가지로 나뉜다.

- 로컬 캐싱
  - Ehcache
  - Caffeine
- 글로벌 캐싱
  - Redis
  - Memcached

---

## Local Cache

우선 로컬 캐시는 말 그대로 애플리케이션 스펙에서 메모리의 일부분을 캐시로 사용하는 것이다.

이 방식은 추후 설명할 Global Cache와 다르게 외부 서버 캐시와 통신할 필요가 없기 때문에 성능이 비교적 좋다.

하지만 애플리케이션 서버의 스펙을 캐시로 잡아먹는 것이기 때문에 추가적인 리소스가 발생하며 이에 따라서 캐싱 정책을 잘 잡아야한다.

Spring Boot 애플리케이션에서 로컬 캐싱을 적용할 수 있는 방법은 크게 두 가지가 있다.

---

## Local Cache의 장단점

`장점` : 속도가 빠르다. 외부 캐시 서버와 통신할 필요가 없기 때문이다.

`단점` : 분산 처리 환경이라면 각 서버마다 다른 캐시 저장소를 사용하기 때문에 별개로 캐시 저장소가 사용된다. (필요에 따라 캐시 저장소 갱신 작업이 요구된다.)

---

## Local Cache - Ehcache

Ehcahce는 Java에서 자체적으로 지원하는 Local Cache이다.

다른 캐시 엔진과 달리 데몬을 가지지 않고 Spring 내부적으로 동작하여 캐싱 처리를 할 수 있다.

---

### Ehcache 캐싱 데이터 저장 방식

- 캐싱할 데이터를 외부 메모리에 저장한다. 저장되는 공간은 아래와 같다.
  - JVM 메모리
  - 서버 메모리(Off-Heap)
  - 서버 Disk

JVM 메모리에 저장한다면 상관없지만 만약 서버 메모리, 서버 디스크에 저장한다면 반드시 직렬화가 되어있어야한다.

말 그대로 JVM내부에서 쓰이는 데이터가 아니라, 외부에 저장되고 불러올 데이터이기 때문에 직렬화/역직렬화를 통해 Java System에서 사용할 수 있게 변환해야하는 것이다.

---

### Ehcache 캐싱 Evict 전략

- LRU (가장 오래 쓰이지 않은 순서)
- LFU (가장 적게 쓰인 순서)
- FIFO (가장 먼저 들어온 순서)

Ehcache는 디스크에도 저장가능하기 때문에 디스크 용량에 따른 전략도 적용할 수 있다.

---

## Local Cache - Caffeine

로컬 캐시를 사용하기로 했다면 대부분 Caffeine을 사용할 것이다. 그 이유는 아래와 같다.

- 캐시 전략에 우선순위를 부여 가능하다.
- 캐시 히트율이 매우 높은 알고리즘인 `Window TinyLFU`를 제공한다.

왜 성능이 좋은지 살펴보자

---

### Caffeine 캐싱 데이터 저장 방식

- JVM Heap 메모리 내에 저장된다.

---

### Caffeine 캐싱 전략

Caffeine 의 캐싱 전략을 살펴보자

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84pKiujtGOpbnpVgIwhpkQ.png)

- `Main Cache`가 존재하며 전체 용량의 99%를 가지고 있다.
  - `Probation Cache`가 존재하며 Main Cache의 80%를 차지하여 `LRU 전략`이 적용되는 공간이다.
  - `Protected Cache`가 존재하며 자주 사용되지 않는 데이터를 가지고 있다. 이 공간의 데이터는 제거되지 않는다.

- `Window Cache`가 존재하여 전체 용량의 1%를 가지고 있다.
  - `새로운 데이터`가 쓰일 때 `가장 먼저` 이 공간에 쓰인다.
  - Window Cache가 꽉차있다면 `LRU` 전략으로 기존 데이터를 쫓아낸다.
    - 이 때 `Tiny LFU` 알고리즘으로 제거되거나, `Probation Cache`에 저장된다.
      - `Probation` 영역에 일정 횟수 이상 접근되면 Protected Cache로 옮겨진다.
        - `Protected Cache` 영역이 꽉차면 오래된 데이터는 제거된다.
        - 이 때 `TinyLFU 알고리즘`에 의해 제거되거나 `Main Cache`의 `Probation Cache` 영역으로 옮겨진다.

TinyLFU의 정책을 살펴보기 전 우선 용어 정리는 다음과 같다.

- `Window Cache`, `Main Cache내의 Protected Cache`로부터 제거되는 데이터는 `Candidate`이다.
- `Main Cache내의 Probation Cahce`에서 제거되는 데이터는 `Victim`이다.

TinyLFU의 정책은 아래와 같다.

- `Candidate Cache` 접근 횟수 > `Victim Cahce` 접근 횟수 == `Victim 제거`
- `Candidate Cache` 접근 횟수 < `Victim Cahce` 접근 횟수 && `Candidate` 접근 횟수가 5회 이하 == `Candidate 제거`
- 둘 중 하나 `랜덤하게 제거`

---

## Local Cache - Ehcache vs Caffeine

[벤치마크 결과](https://github.com/ben-manes/caffeine/wiki/Benchmarks)

위 벤치마크 결과를 본다면 압도적으로 카페인 캐시가 성능이 좋게 나온다.

성능이 좋다고 무조건 쓰는게 좋은 것은 아니므로 기존 환경을 잘 고려하여 선택하면 될 것같다.

# Caffeine Cahce 적용 후기

실제 운영 중인 프로젝트에 카페인 캐시를 적용해보기로 했다.

그 중에서 홈 API에 캐싱을 적용하기 적합하다고 생각했는데

- 트래픽이 많은 서비스가 아니기 때문에 며칠에 한 번씩 변경이 생긴다.

- 며칠에 한 번씩 변경이 생기지 않는 이상 매번 같은 데이터를 DB에서 조회한다.

이 두 가지가 그 이유이다. 사실 응답 속도가 그리 느린건 아니였지만 우선 배운 내용을 어떻게 적용하는지까지 경험해보고 싶었기 때문에 도입했다.

그러면 캐시를 바르기 전 응답 시간을 보자

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/cache/beforecache.png?raw=true)

`72ms`가 소요되고 있다. 그러면 이제 캐시를 적용해보자.

---

## Spring Boot + Caffeine Cache

코드로 적용하기 위한 작업은 간단하다.

- 라이브러리 의존성 받아오기
- Config Bean 등록
- CacheType 설정
- Caching 대상 지정

---

### 1. 의존성 받아오기

우선 아래 의존성을 추가해줘야한다.

```groovy
implementation 'org.springframework.boot:spring-boot-starter-cache'
implementation 'com.github.ben-manes.caffeine:caffeine'
```

---

### 2. Config Bean 등록

아래 코드로 캐시 설정에 대한 내용을 Bean으로 등록해줘야한다.

```java
import com.github.benmanes.caffeine.cache.Caffeine;
import org.springframework.cache.CacheManager;
import org.springframework.cache.caffeine.CaffeineCache;
import org.springframework.cache.support.SimpleCacheManager;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import usw.suwiki.global.config.cache.CacheType;

import java.util.Arrays;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

@Configuration
public class CacheConfig {

    @Bean
    public CacheManager cacheManager() {
        SimpleCacheManager cacheManager = new SimpleCacheManager();
        List<CaffeineCache> caches = Arrays.stream(CacheType.values())
                .map(cache -> new CaffeineCache(cache.getCacheName(), Caffeine.newBuilder().recordStats()
                                .expireAfterWrite(cache.getExpiredAfterWrite(), TimeUnit.SECONDS)
                                .maximumSize(cache.getMaximumSize())
                                .build()
                        )
                )
                .collect(Collectors.toList());
        cacheManager.setCaches(caches);
        return cacheManager;
    }
}
```

---

### 3. CacheType 설정

아래 코드처럼 어떻게 캐싱할것인지 캐싱 정책은 어떻게 할 것인지 상세 내용을 갖는 enum을 만들어야한다.

- 캐시 이름은 도메인 이름으로 설정했고 

- 캐시 만료 시간은 60초로 지정했으며

- 캐싱할 수 있는 데이터의 수는 1000개로 지정한다.

```java
import lombok.Getter;

@Getter
public enum CacheType {
    LECTURE("lecture", 60, 1000);

    CacheType(String cacheName, int expiredAfterWrite, int maximumSize) {
        this.cacheName = cacheName;
        this.expiredAfterWrite = expiredAfterWrite;
        this.maximumSize = maximumSize;
    }

    private final String cacheName;
    private final int expiredAfterWrite;
    private final int maximumSize;
}
```

---

### 4. 캐싱을 적용할 메서드 지정

홈을 조회하는 API에 대한 내용을 캐싱하기로 한 내용이다. 

```java
    @Cacheable(cacheNames = "lecture")
    @ApiLogger(option = "lecture")
    @GetMapping("/all")
    public ResponseEntity<LectureAndCountResponseForm> findAllLectureApi(
            @RequestParam(required = false) String option,
            @RequestParam(required = false) Integer page,
            @RequestParam(required = false) String majorType)
        {
            ...
        }
```


## 적용 후 성능은?

![](https://github.com/K-Diger/K-Diger.github.io/blob/main/images/cache/aftercache.png?raw=true)

`33ms`로 기존 `72ms`에서 거의 두 배 가깝게 빠르게 성능이 개선되었다!

---

# Global Cache

글로벌 캐시는 외부에 캐시서버를 배치한 후 해당 캐시서버에 여러 서버가 접근하여 캐싱 데이터를 사용하는 것이다.

이 글에서 글로벌 캐시에 대해서는 가볍게 알아보기로 한다.

---

## Global Cache의 장단점

`장점` : 로컬 캐시 방식에서 발생하는 데이터 정합성 문제를 해결할 수 있다.

`단점` : 네트워크를 경유하기 때문에 성능이 비교적 좋지 않으며 캐시서버의 장애 발생 시 그 에러가 모든 서버에 전파될 수 있다.

---

## Global Cache - Redis



---

## Global Cache - Memcached


---

## 왜 Global Cache인가? (Local Cache vs Global Cache)