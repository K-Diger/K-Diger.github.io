---

title: 성능 개선의 근본 - 캐시
date: 2023-08-15
categories: [Cache]
tags: [Cache]
layout: post
toc: true
math: true
mermaid: true

---

# Cache

`캐싱` 사실 컴퓨터 구조 수업을 들을때도 배우는 개념이다. 그 만큼 컴퓨터 환경에서의 가장 근본적인 성능 개선의 방법 중 하나이다.

애플리케이션 관점에서도 똑같다. DB와 통신하는 작업은 당연하게도 비용이 크게 측정된다. 애플리케이션 내부에서 처리하는 것이 아닌 외부와 통신하는 과정이기 때문이다.

그래서 자주 쓰이고 자주 변하지 않는 데이터는 캐싱을 통해 DB조회 빈도를 줄이는 캐싱을 적용한다면 성능 개선을 이뤄낼 수 있다.

---

# Local Cache | Global Cache

캐싱의 방법은 크게 두 가지로 나뉜다.

- 로컬 캐싱
  - Ehcache
  - Caffeine
  - Memcached
- 글로벌 캐싱
  - Redis

---

## Local Cache

우선 로컬 캐시는 말 그대로 애플리케이션 스펙에서 메모리의 일부분을 캐시로 사용하는 것이다.

이 방식은 추후 설명할 Global Cache와 다르게 외부 서버 캐시와 통신할 필요가 없기 때문에 성능이 비교적 좋다.

하지만 애플리케이션 서버의 스펙을 캐시로 잡아먹는 것이기 때문에 추가적인 리소스가 발생하며 이에 따라서 캐싱 정책을 잘 잡아야한다.

Spring Boot 애플리케이션에서 로컬 캐싱을 적용할 수 있는 방법은 크게 두 가지가 있다.

## Local Cache의 장단점

`장점` : 속도가 빠르다. 외부 캐시 서버와 통신할 필요가 없기 때문이다.

`단점` : 분산 처리 환경이라면 각 서버마다 다른 캐시 저장소를 사용하기 때문에 별개로 캐시 저장소가 사용된다. (필요에 따라 캐시 저장소 갱신 작업이 요구된다.)

## Local Cache - Ehcache

Ehcahce는 Java에서 자체적으로 지원하는 Local Cache이다.

다른 캐시 엔진과 달리 데몬을 가지지 않고 Spring 내부적으로 동작하여 캐싱 처리를 할 수 있다.

또한 같은 로컬 캐시여도 별도로 구동하는 Memcached와는 다르게 서버 애플리케이션과 같은 라이프사이클을 사용하기 때문에 더 간편하다.

### Ehcache 캐싱 데이터 저장 방식

- 캐싱할 데이터를 외부 메모리에 저장한다. 저장되는 공간은 아래와 같다.
  - JVM 메모리
  - 서버 메모리(Off-Heap)
  - 서버 Disk

JVM 메모리에 저장한다면 상관없지만 만약 서버 메모리, 서버 디스크에 저장한다면 반드시 직렬화가 되어있어야한다.

말 그대로 JVM내부에서 쓰이는 데이터가 아니라, 외부에 저장되고 불러올 데이터이기 때문에 직렬화/역직렬화를 통해 Java System에서 사용할 수 있게 변환해야하는 것이다.

### Ehcache 캐싱 Evict 전략

- LRU (가장 오래 쓰이지 않은 순서)
- LFU (가장 적게 쓰인 순서)
- FIFO (가장 먼저 들어온 순서)

Ehcache는 디스크에도 저장가능하기 때문에 디스크 용량에 따른 전략도 적용할 수 있다.

---

## Local Cache - Caffeine

로컬 캐시를 사용하기로 했다면 대부분 Caffeine을 사용할 것이다. 그 이유는 아래와 같다.

- 캐시 전략에 우선순위를 부여 가능하다.
- 캐시 히트율이 매우 높은 알고리즘인 `Window TinyLFU`를 제공한다.

왜 성능이 좋은지 살펴보자

### Caffeine 캐싱 데이터 저장 방식

- JVM Heap 메모리 내에 저장된다.

### Caffeine 캐싱 전략

Caffeine 의 캐싱 전략을 살펴보자

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84pKiujtGOpbnpVgIwhpkQ.png)

- `Main Cache`가 존재하며 전체 용량의 99%를 가지고 있다.
  - `Probation Cache`가 존재하며 Main Cache의 80%를 차지하여 `LRU 전략`이 적용되는 공간이다.
  - `Protected Cache`가 존재하며 자주 사용되지 않는 데이터를 가지고 있다. 이 공간의 데이터는 제거되지 않는다.

- `Window Cache`가 존재하여 전체 용량의 1%를 가지고 있다.
  - `새로운 데이터`가 쓰일 때 `가장 먼저` 이 공간에 쓰인다.
  - Window Cache가 꽉차있다면 `LRU` 전략으로 기존 데이터를 쫓아낸다.
    - 이 때 `Tiny LFU` 알고리즘으로 제거되거나, `Probation Cache`에 저장된다.
      - `Probation` 영역에 일정 횟수 이상 접근되면 Protected Cache로 옮겨진다.
        - `Protected Cache` 영역이 꽉차면 오래된 데이터는 제거된다.
        - 이 때 `TinyLFU 알고리즘`에 의해 제거되거나 `Main Cache`의 `Probation Cache` 영역으로 옮겨진다.

TinyLFU의 정책을 살펴보기 전 우선 용어 정리는 다음과 같다.

- `Window Cache`, `Main Cache내의 Protected Cache`로부터 제거되는 데이터는 `Candidate`이다.
- `Main Cache내의 Probation Cahce`에서 제거되는 데이터는 `Victim`이다.

TinyLFU의 정책은 아래와 같다.

- `Candidate Cache` 접근 횟수 > `Victim Cahce` 접근 횟수 == `Victim 제거`
- `Candidate Cache` 접근 횟수 < `Victim Cahce` 접근 횟수 && `Candidate` 접근 횟수가 5회 이하 == `Candidate 제거`
- 둘 중 하나 `랜덤하게 제거`

---

## Local Cache - Ehcache vs Caffeine

[벤치마크 결과](https://github.com/ben-manes/caffeine/wiki/Benchmarks)

위 벤치마크 결과를 본다면 압도적으로 카페인 캐시가 성능이 좋게 나온다.

성능이 좋다고 무조건 쓰는게 좋은 것은 아니므로 기존 환경을 잘 고려하여 선택하면 될 것같다.

---

# Global Cache