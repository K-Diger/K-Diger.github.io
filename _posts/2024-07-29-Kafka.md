---

title: 카프카와 친해지기
date: 2024-07-29
categories: [Kafka]
tags: [Kafka]
layout: post
toc: true
math: true
mermaid: true

---

# 참고 자료

- [Kafka Producer Internal](https://d2.naver.com/helloworld/6560422)
- [Kafka Consumer Internal](https://d2.naver.com/helloworld/0974525)
- [Kafka Network Internal](https://d2.naver.com/helloworld/0853669)

---

# 순서

1. 프로듀서와 친해지기
2. 컨슈머와 친해지기
3. 카프카 생태계의 네트워크 알아보기

---

# 프로듀서와 친해지기

카프카 프로듀서의 구성요소는 3가지이다.

- Producer Client
- RecordAccumulator
- Sender

---

## 1. Producer Client

Java/Kotlin 코드로 `Producer`의 `send()`메서드로 레코드를 전송한다.

send()호출 시 레코드와 전송 완료 후의 실행할 콜백을 지정할 수 있다. 이 메서드를 호출하면 `직렬화`, `파티셔닝`, `압축`작업이 이루어진다.

### 1.1 Producer Client - Serializer

레코드의 Key, Value는 `Byte Array로` 변환된다. 이 때 `Serializer`는 `key.serializer`, `value.serializer`로 각각 Key, Value에 대한 직렬화 방식을 지정할 수 있다.

```java
configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
```

Serializer의 종류는 아래와 같다.

- String
- ByteArray
- ByteBuffer
- Bytes
- Double
- Integer
- Long

---

### 1.2 Producer Client - Partitioning

**레코드**는 **지정된 파티셔너에 의해 어떤 파티션으로 보내질지 정해진다.**

파티셔너는 레코드의 담긴 Key 통해 파티션을 확인하고 명시한 파티션이 없다면 라운드 로빈으로 파티션을 선택하여 저장한다.

`partitioner.class`를 설정하여 파티셔너를 지정할 수 있고 지정하지 않으면 `org.apache.kafka.clients.producer.internals.DefaultPartitioner`가 사용된다.

레코드에 지정된 파티션이 없는 경우 DefaultPartitioner는 다음과 같이 동작한다.

- Key 값이 있는 경우 : Key 값의 Hash 값을 이용해서 파티션을 할당한다.
- Key 값이 없는 경우 : Round-Robin 방식으로 파티션이 할당된다.

### 1.3 Producer Client - Compression

레코드를 압축하여 네트워크 비용과 디스크 저장 비용을 줄인다. `compression.type`옵션을 통해 압축 시 사용할 코덱을 지정할 수 있고 `기본값은 none(압축하지 않음)`이다.

---

## 2. RecordAccumulator

`send()`메서드를 호출하면 Broker로 바로 전송되는 것이 아니라 `RecordAccumulator`에 저장된다.

### 2.1 RecordAccumulator - append()

RecordAccumulator는 `batches`라는 `Map`을 가지고 있는데, 이 `Key`는 `TopicPartition`이고, `Value`는 `Deque<RecordBatch>`이다. 즉, 각 파티션에 대한 Record 묶음을 들고 있는 것이다.

`Record`의 `Serialized Size`를 검사한 후 `Serialized Size`가 `max.request.size` 혹은 `buffer.memory` 설정값보다 크면 `RecordTooLargeException`이 발생한다. 검증을 마친 후에는 `append()`메서드를 통해 저장된다.

#### append() 호출 시

![](https://d2.naver.com/content/images/2020/08/62686a80-b576-11ea-8839-3eb52b31945d.png)

1. `batches`에서 추가될 레코드가 들어갈 파티션의 `Deque`찾는다.
2. 해당 `Deque의 Last`에 접근하여 `레코드 배치`를 확인한 후 추가될 `레코드`를 저장할 공간이 있는지 확인한다.
3. 여유 공간이 있으면 `레코드`를 `RecordBatch`에 추가한다.
4. 여유 공간이 없으면 `새로운 레코드 배치`를 생성하고 Last에 저장한다.
   5. 이 때 `레코드 배치`를 생성할 때 `버퍼 풀`에서 `레코드 배치`가 사용할 `ByteBuffer`를 받아온다. `버퍼풀`에 여유가 있으면 최대 `max.block.ms`만큼 블락된다. 이 시간이 지나도 해결이 안되면 `TimeoutException`이 발생한다.
6. `compression.type`이 지정되어있으면 `레코드`가 `레코드 배치`로 삽입될 때 압축된다.

---

## 3. Sender

`RecordAccumulator`에 저장된 레코드를 실질적으로 `브로커에 전송`하는 역할을 수행한다. 이는 비동기적으로 이루어지며 브로커에게 응답을 받은 후 `레코드 전송 시 설정한 콜백에 대한 응답`을 전달하기도 한다.

### 3.1 Sender Thread

- RecordAccumulator에서 레코드를 꺼낸다. 이 때 `drain()`로 꺼내오게 되는데, 각 `브로커별로 전송할 RecordBatch의 List`를 얻을 수 있다.

#### 3.1.1 Sender Thread - drain()

1. `drain()`에서는 각 `브로커 노드에 속한 TopicPartition 목록`을 얻어온다.
2. 그 후 `각 노드가 속한 TopicPartition`을 보면서 가장 앞에 있는 `RecordBatch`를 꺼낸다.
3. 꺼낸 `RecordBatch`를 `RecordBatch List에 추가`한다.
   4. 이 때 `max.request.size`가 넘지 않을 때 까지 모은다.

이렇게 하면 각 `브로커 노드별`의 `RecordBatch List`가 만들어진다.

#### 3.1.2 Sender Thread - ProducerRequest

`drain()`과정을 통해 만들어진 RecordBatchList가 하나의 ProducerRequest로 만들어져 전송된다.

`ProducerRequest`는 `InFlightRequest`라는 `각 노드의 Deque에 저장`되고 저장된 순서대로 실제 브로커 노드에 전송된다.

브로커 노드로 레코드를 전송할 때는 Multiplexing 방식으로 동작해서 별도의 쓰레드를 사용하지 않고, Sender Thread에서 비동기적으로 이뤄진다.

`InFlightRequests Deque`의 Size는 `max.in.flight.requests.per.connection` 설정값에 의해서 정해진다. 이 값은 `ProducerClient`가 `하나의 Broker`로 `동시에 전송할 수 있는 요청 수`를 의미한다.

---

# 컨슈머와 친해지기
