---

title: Index랑 친한 척 하기 (MySQL B-Tree)

date: 2023-07-07
categories: [JPA, MySQL, Index]
tags: [JPA, MySQL, Index]
layout: post
toc: true
math: true
mermaid: true

---

# 문제 상황

현재 진행하는 프로젝트에서 특정 키워드가 포함된 레코드를 모두 조회하는 요구사항이 있었다.

현재 레코드 수는 아래 그림과 같이 약 160만개 이고, 매 1시간마다 800 ~ 1200개의 레코드가 추가되는 테이블을 사용하고 있다.

![img.png](https://..%2Fimages%2Findex%2Fimg.png)

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/b5652947-38a4-42c4-b6e6-a909d65e0b52)

위 요구사항을 해결하기 위한 로직을 처리하는데 아래와 같이 12초 ~ 13초의 시간이 소요되어 이를 개선하고자 한다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/dbd5d34f-8329-42dd-b23d-848f96bb9cc0)

---

# 문제 분석

문제의 원인이 무엇인지 살펴보기 위해 쿼리를 살펴보면 아래와 같다.

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/b95ff053-6f4f-4142-8e8f-f2a61098a917)

**news**라는 테이블의 모든 레코드를 Full Scan하면서 조건에 맞는 레코드를 가져오는 로직이다.

여기서 문제가 발생한 것이였다. 레코드 수가 너무 많기 때문에 A-Z까지 도달하는 시간 자체가 길어진 것이다.

이를 해결하려면 어떻게 해야할까? 내가 생각했던 해결책은 아래와 같다.

- 특정 조건에 부합하는 레코드를 포인터로 찝어서 조회를 수행한다. (커서 페이징과 유사한 해결방식)
- DB에 인덱스를 적용하여 조회 시 성능을 더 높일 수 있도록한다. (인덱스가 뭔지는 구체적으로 몰랐다.)

일단 첫 번째 방법은 차선책으로 해결하기로 하고 여기저기서 많이 들어본 인덱스를 활용하여 해결해보기로 결정했다.

---

# 해결 과정

**보조 인덱스를 어떤 컬럼을 지정해야하는가?** 를 고민하기 시작했다.

인덱싱의 원리의 따르면 보조 인덱스는 **조회할 때 사용할 조건 컬럼**이 되어야하고 **되도록 중복되지 않는 것**이 성능 개선에 더 좋다고 한다.

위 사항을 고려하여 조회할 테이블의 레코드를 살펴보면 어떤 것을 보조 인덱스로 지정할 지 결정하면된다.

## 인덱스란?

**Real MySQL**이라는 책을 읽고있다고 가정해보자.

여기서 나는 **인덱스**라는 챕터의 내용을 읽고싶으면 어떻게 하는가?

- 첫 장부터 **인덱스 챕터**가 나올 때 까지 일일히 넘긴다.
- 목차를 활용해서 **인덱스 챕터**가 나오는 페이지를 확인하고 이동한다.

둘 중 어떤 방법이 더 빠르게 **인덱스 챕터**를 찾을 수 있을까?

만약에 페이지 수가 굉장히 적고 첫 페이지부터 인덱스 챕터가 등장한다면 첫 번째 방법이 빠를 것이다.

하지만 보통 책은 그렇지 않다. 여러 내용을 소개하는 챕터가 분류되어있고 책의 분량도 다양하게 제작된다.

따라서 보편적으로는 목차를 읽고 원하는 챕터가 나오는 페이지로 넘긴다.

이 상황을 DBMS의 데이터를 조회할 때 적용하는 것이 **인덱스** 방식이다.

**인덱스 == 책의 목차 페이지** 라고 생각하면 좋을 것 같다.

## 인덱스가 무작정 좋기만 할까?

### 인덱스가 독이 될 수 있는 상황 1

아까 들었던 예시에서 찾고자하는 대상인 "인덱스 챕터"에 관한 데이터가 많다면 문제가 생긴다.

즉, 10개의 챕터 중 **"인덱스"** 라는 단어가 들어간 챕터가 10개라면? 이런식으로 찾아서는 인덱스가 거의 무용지물이다. 오히려 일일히 책을 뒤져보는 것 보다 **성능이 더 느린 상황이 발생**할 수도 있다.

### 인덱스가 독이 될 수 있는 상황 2

또한 기존 책이 1000페이지라고 했을 때 인덱스 역할을 하는 **목차**를 나타내는 페이지가 없다면 1000쪽으로 끝날 것이다.

하지만, 인덱스를 추가하면서 부가적인 쪽수가 늘어나게 된다.

DBMS에도 마찬가지로 인덱스를 관리하기 위한 **추가적인 리소스가 소모**된다.

인덱스는 일반적으로 10% ~ 20%의 공간을 추가로 요구한다.

### 인덱스가 독이 될 수 있는 상황 3

책의 내용이 1000페이지인데 **500페이지 쯤에서 내용을 추가해야한다**고 해보자

이 상황에선 당연하게도 **페이지의 내용을 추가하는 것**과 더불어 **인덱스를 관리하는 목차 또한 모두 고쳐**야한다.

이 역시 **인덱스의 내부 구현이 LinkedList와 유사한 B-Tree방식**으로 구현되어있기 때문이다.

---

결론적으로 인덱스는 대용량 테이블에 적용한다면 성능 개선을 기대할 수 있지만 그렇지 않다면 오히려 리소스를 더 사용하고, 조회 성능 까지도 느리게 만들 수 있다.

또한, 삽입/변경/삭제 등이 자주 일어나는 테이블에는 적절한 방법이 아니다.

## 인덱싱 알고리즘 종류

- B-Tree
- R-Tree
- 전문 검색
- 함수 기반
- 멀티 밸류
- 클러스터링
- 유니크
- 외래키

## B-Tree 인덱스 구조

MySQL에서는 **B-Tree(Balanced-Tree)**, **HashMap**으로 구조화되어있다. DBMS의 종류에 따라 다르겠지만 최근에는 Fractal-Tree과 로그 기반의 Merge-Tree으로 구조화 되는 경우도 있다.

B-Tree는 아래 그림과 같이 구성되어있다. (by Real MySQL)

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/f5eb44b9-6493-4795-90ef-024d42268183)

**루트** 노드, **브랜치** 노드, **리프** 노드가 트리 형태로 이어져 있으며 **각 노드는 16KB**인 페이지다.

리프노드는 실제 데이터 레코드를 찾아가기 위한 주소를 가지고 있다.

데이터의 파일내의 레코드는 INSERT된 순서대로 저장되는 것으로 볼 수 있지만 레코드가 삭제되어 빈 공간이 생기면 그 다음의 INSERT는 그 자리로 들어가게 되므로 항상 INSERT된 순서로 저장되어 있지는 않다.

### B-Tree 인덱스 키 추가 과정

- 저장될 키 값을 이용해 B-Tree에 **적절한 삽입점을 검색**한다.

- 저장위치가 결정되면 **레코드의 키 값**과 **레코드의 주소 정보**를 B-Tree의 **리프 노드에 저장**한다.

> 리프 노드가 꽉 차서 저장할 수 없을 때는 리프 노드가 분리 되어야 한다. 그리고 이 때 상위 브랜치 노드까지 처리 범위가 넓어진다.

위 이유로 인해 B-Tree는 상대적으로 쓰기작업(새로운 키 추가)에 비용이 많이 든다.

B-Tree기반의 인덱싱이 **INSER나 UPDATE의 성능**에 미치는 영향은

테이블에 **새로운 레코드를 추가**하는 **작업 비용을 1**이라고 했을 때 **인덱스를 추가**하는 **작업 비용은 1.5** 정도로 예측한다.

따라서 테이블에 **인덱스가 3개**인 경우에는 하나의 레코드 삽입 시

`인덱스 추가 비용 * 인덱스 갯수 + 삽입 비용`

`1.5 * 3 + 1 = 5.5`로 예측한다.

### B-Tree 인덱스 키 삭제 과정

- 키 값이 저장된 리프노드를 찾아 **삭제 마크**를 남긴다.

삭제 마킹된 **키 공간은 재활용하거나 방치**하는 것이 가능하다.

이 마킹 또한 DISK I/O가 필요한 작업으로 버퍼링 될 수 있다. (지연처리 가능)

### B-Tree 인덱스 키 변경

- 키 값을 삭제한다.

- 다시 새로운 키를 추가한다.

인덱스의 키 값은 값에 따라 저장될 위치가 결정되기 때문에 B-Tree의 키가 변경되는 경우에 인덱스 상의 Key값을 변경할 수 없다.

따라서 위 과정처럼 삭제->추가의 과정을 거쳐 변경 작업을 수행하며 삭제와 마찬가지로 지연 처리가 가능하다.

### B-Tree 인덱스 키 검색

CUD 작업에 추가 비용을 감당하면서까지 사용하려는 이유가 검색 성능을 위해서이다.

- 루트 노드부터 검색을 시작한다

- 브랜치 노드를 거친다

- 리프 노드까지 이동하며 비교 작업을 수행한다.

위 **트리 탐색**과정을 거쳐 검색 작업을 수행하는데 이 작업은 UPDATE, DELETE를 처리할 때에도 사용된다.(SELECT FOR UPDATE)

B-Tree를 활용한 검색은 100% 일치하는 경우에만 적용될 수 있다. 인덱스를 구성하는 키 값의 뒷부분만 검색하는 용도로는 사용할 수 없다.

또한 인덱스의 키 값에 변형이 가해진다면 인덱스를 통한 검색 기능을 사용할 수 없다.

변형된 값은 B-Tree 인덱스에 존재하는 값이 아니기 때문이다.

따라서 **함수나 연산을 수행한 결과**로 **정렬, 검색 하는 작업**은 B-Tree의 **성능 개선을 기대할 수 없다.**

### B-Tree 인덱스 페이지의 크기

기본적으로 16KB이다. (innodb_page_size를 확인해보면 된다.)

리프 노드의 주소가 대략 6바이트에서 12바이트로 구성 된다고 할 때 한 페이지에 등록될 수 있는 Key는 다음과 같다.

16Byte(인덱스 Key 크기) + 12Byte(리프 노드의 주소 크기)

그러면 하나의 인덱스 페이지(16KB)에 몇 개의 키를 저장할 수 있을까?

`16 * 1024(인덱스 페이지의 크기) / 16(인덱스 Key의 크기) + 12(리프 노드 주소 크기) = 585개이다.`

여기서 인덱스 Key 값이 2배로 커진다면 한 페이지에 인덱스 키를 16 * 1024 / 32 + 12 = 372개 저장할 수 있게 된다.

SELECT 쿼리가 레코드 500개를 읽어와야한다면 인덱스 Key 크기가 16Byte일 때는 한 페이지만 읽어도 조회가 가능하지만

인덱스 Key 크기가 32Byte일 때는 두 페이지 까지 가야 조회가 가능하다.

따라서 인덱스를 구성하는 Key의 값의 크기가 커진다면 디스크로부터 읽는 횟수가 늘어나 성능저하가 발생한다.

### B-Tree Depth

인덱스의 B-Tree 깊이가 의미하는 것은 다음과 같다. 만약 B-Tree의 깊이가 3인경우 최대 가질 수 있는 Key 값은

`585 * 585 * 585 = 약 2억` 과 같다. (위에서 언급한 인덱스 페이지의 크기와 인덱스 Key의 크기를 사용했을 때를 가정했다.)

만약 Key값이 32Byte로 늘어난다면 `372 * 372 * 372 = 5천만` 과 같다.

이 역시 인덱스의 Key 값이 커지면 인덱스 페이지에 들어갈 그 자체의 수도 줄어들 뿐만 아니라 Depth가 깊어지기 때문에 디스크I/O가 많이 발생하여 성능 저하가 일어난다.

### Selectivity(선택도) == Cardinality(기수성)

두 용어는 거의 같은 의미로 사용되고, `모든 인덱스 Key 값 중 유니크한 값의 수`를 말한다.

인덱스 키 값 중 중복된 값이 많아지면 많아질수록 Cardinality는 낮아지고 선택도 또한 떨어진다.

인덱스는 선택도가 높을수록 검색 대상이 줄어들기 때문에 빠른 성능을 나타낼 수 있다.

하지만 선택도가 낮더라도 정렬, 그룹화 등을 위해 인덱스를 만드는 것이 더 나을 수도 있다.

**인덱스는 항상 검색에만 사용되는 것이 아닌 것**을 인지해야한다.

또한 [여러 컬럼을 Index로 지정할 때는 카디널리가 높은 순으로 인덱스를 생성하는 것이 더 효율적이다.](https://jojoldu.tistory.com/243)

이 말인 즉슨, **중복되지 않고 고유한 값이 많은 컬럼을 가장 우선순위로 인덱싱**을 하라는 것이다.


## 클러스터형 인덱스 구조

클러스터형 인덱스는 **국어사전**과 비슷하다.

즉, 그 자체로 이미 정렬되어있어 인덱스 자체가 그 책의 내용과 같다.

클러스터형 인덱스는 **테이블 당 한 개**만 생성가능하며, 레코드를 인덱스로 지정한 열에 맞춰 자동으로 정렬한다.

클러스터형 인덱스는 PK를 지정한다. 따라서 **클러스터형 인덱스 == PK** 라고 생각하면 된다.

`테이블 생성 시에 UK를 지정하면 보조 인덱스가 생성된다.`

---

보통 Spring, JPA로 개발을 하다보면 기계적으로 클러스터형 인덱스(PK)를 Auto_Incremnet 옵션을 사용하곤 한다.

그런데 Bigint 타입의 해당 옵션이 아닌, UUID등과 같이 String 타입을 PK로 지정하면 어떻게 순서가 유지될까?

앞서 말했듯이 클러스터형 인덱스는 영어사전처럼 **순서대로** 정렬한다고 했다.

따라서 데이터가 삽입된 순서에 관계없이 무조건 해당 String 값으로 정렬을 해놓는다.

이래서 String 타입으로 PK를 사용하지 않는 것도 있다. 삽입을 하면 추가적으로 인덱스를 정렬해줘야 하기 때문에 여기서 리소스가 발생하기 때문이다.

---

# 인덱스 적용 후 성능 개선

## 실행 계획을 통한 성능 분석

### Index를 적용하지 않았을 때

```mysql
EXPLAIN ANALYZE
SELECT *
FROM news
WHERE created_at BETWEEN '2023-07-07 10:00:00' and '2023-07-07 11:00:00';
```

위와 같은 쿼리를 날렸을 때의 결과는 아래와 같다.

```text
-> Filter: (news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')  (cost=83282.06 rows=26888) (actual time=7404.655..19644.905 rows=2027 loops=1)
    -> Table scan on news  (cost=83282.06 rows=242017) (actual time=5.829..19139.414 rows=305977 loops=1)
```

수행 시간이 약 5.8초로 측정되었다.

### Index를 적용했을 때 성능 분석

```text
-> Index range scan on news using index_created_at over ('2023-07-07 10:00:00.000000' <= created_at <= '2023-07-07 11:00:00.000000'), with index condition: (news.created_at between '2023-07-07 10:00:00' and '2023-07-07 11:00:00')  (cost=2088.81 rows=2027) (actual time=2.678..57.552 rows=2027 loops=1)
```

수행 시간이 약 2.6초로 측정되었다.

비용 및 수행 시간이 현저하게 감소되었다.

```mysql
CREATE INDEX news_index ON news(created_at);
ANALYZE TABLE news;
```

위 구문으로 Index를 적용하였다. 인덱스 대상 컬럼은 created_at이다.

created_at은 밀리초 단위까지 기록하기 때문에 현재 프로젝트의 서버에서는 중복되지 않는 값일 뿐만 아니라 해당 컬럼을 조건절로 사용하기 때문에 지정하였다.

그리고 아래와 같이 JPA에서 인덱싱을 매핑시켜주면 적용은 끝난다.

```kotlin
@Table(
    name = "news",
    indexes = [
        Index(name = "news_index", columnList = "created_at"),
    ]
)
```

## 적용 후 실행 결과

![](https://github.com/K-Diger/K-Diger.github.io/assets/60564431/3198996e-f9f8-4188-9ce8-b2cc555d0d84)

아까 **13초** 걸리던 로직이 **1.3초로 90%가 개선**되었다....

인덱스의 효과는 엄청나다!

# 인덱스 사용 시 주의할 점

- 이미 돌아가고 있는 대용량 테이블에 인덱스를 생성하면 엄청나게 시간이 소요될 수 있다.
